{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform inference on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab513\\AppData\\Roaming\\Python\\Python38\\site-packages\\napari\\_qt\\__init__.py:38: UserWarning: napari was tested with QT library `>=5.12.3`.\n",
      "The version installed is 5.9.7. Please report any issues with this specific QT version at https://github.com/Napari/napari/issues.\n",
      "  warn(message=warn_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Disable GPU (if it is used elsewhere)\n",
    "# try:\n",
    "#     # Disable all GPUS\n",
    "#     tf.config.set_visible_devices([], 'GPU')\n",
    "#     visible_devices = tf.config.get_visible_devices()\n",
    "#     for device in visible_devices:\n",
    "#         assert device.device_type != 'GPU'\n",
    "# except:\n",
    "#     # Invalid device or cannot modify virtual devices once initialized.\n",
    "#     pass\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model, layers, models\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import Iterator, ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import Iterator, ImageDataGenerator\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import skimage.transform\n",
    "\n",
    "import napari\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Here we load the test set of Bright Field images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Generates images and masks for performing data augmentation in Keras.\n",
    "    We inherit from Sequence (instead of directly using the keras ImageDataGenerator)\n",
    "    since we want to perform augmentation on both the input image AND the mask \n",
    "    (target). This mechanism needs to be implemented in this class. This class\n",
    "    also allows to implement new augmentation transforms that are not implemented\n",
    "    in the core Keras class (illumination, etc.).\n",
    "    See : https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    and https://stackoverflow.com/questions/56758592/how-to-customize-imagedatagenerator-in-order-to-modify-the-target-variable-value\n",
    "    for more details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_set, # input images and masks\n",
    "                 n_channels_ims=1, n_channels_masks=1,\n",
    "                 batch_size: int=4, dim: tuple=(512, 512),\n",
    "                 n_channels: int=1, # informations \n",
    "                 normalize=True, reshape=False, crop=None, # preprocessing params\n",
    "                 restrict_to=\"\", separate_directories=False): # data augmentation params\n",
    "        \"\"\"\n",
    "        X_set (list, array or str): pointer to the images (Bright-Field). If str\n",
    "        the string is assumed to be pointing at some directory.\n",
    "        Y_set (list; array or str): pointer to the masks (target). If str\n",
    "        the string is assumed to be pointing at some directory.\n",
    "        batch_size (int): size of the batch\n",
    "        dim (tuple): dimension of the images\n",
    "        n_channels (int) : number of channels of the images (1 for TIF)\n",
    "        shuffle (bool): Shuffle the dataset between each training epoch\n",
    "        normalize (bool): normalize the images and masks in the beginning\n",
    "        reshape (bool): reshape the images and masks to (dim, dim, n_channels)\n",
    "        histogram_equalization (bool): perform histogram equalization to improve\n",
    "        rendering using opencv\n",
    "        horiz_flip_percent ()\n",
    "        vert_flip_percent\n",
    "        \"\"\"\n",
    "        # super().__init__(n, batch_size, shuffle, seed)\n",
    "        self.dim = dim\n",
    "        self.im_size = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_channels_ims = n_channels_ims\n",
    "        self.n_channels_masks = n_channels_masks\n",
    "        self.separate_directories = separate_directories        \n",
    "        \n",
    "        self.restrict_to = restrict_to\n",
    "\n",
    "        # build the X_set in an array. If X_set is a directory containing images\n",
    "        # then self.X_set doesn't contains the images but the file names, but it\n",
    "        # is transparent for the user.       \n",
    "        self.from_directory_X = True\n",
    "        self.X_dir = X_set # path to the images dir\n",
    "        self.X_set = []\n",
    "        if self.restrict_to == \"\" and not self.separate_directories:\n",
    "            directory = self.alphanumeric_sort(os.listdir(X_set))\n",
    "            for k in range(0, len(directory), self.n_channels_ims):\n",
    "                self.X_set.append(np.array(directory[k:k+self.n_channels_ims]))\n",
    "            self.X_set = np.array(self.X_set)\n",
    "        elif self.restrict_to == \"\" and self.separate_directories:   # different channels in separate directories\n",
    "            assert len(self.X_dir) == self.n_channels_ims  # number of directories should mathc the number of channels\n",
    "            for k in range(0, len(os.listdir(self.X_dir[0]))):\n",
    "                channels = []\n",
    "                for chan in range(self.n_channels_ims):\n",
    "                    channels.append(self.alphanumeric_sort(os.listdir(self.X_dir[chan]))[k])\n",
    "                self.X_set.append(np.array(channels))\n",
    "            self.X_set = np.array(self.X_set)\n",
    "            print(self.X_set.shape)\n",
    "        else:\n",
    "            directory = self.alphanumeric_sort(os.listdir(X_set))\n",
    "            for k in range(0, len(directory), self.n_channels_ims):\n",
    "                if directory[k].startswith(self.restrict_to):\n",
    "                    self.X_set.append(np.array(directory[k:k+self.n_channels_ims]))\n",
    "            self.X_set = np.array(self.X_set)\n",
    "        \n",
    "        # Preprocessing parameters\n",
    "        self.normalize = normalize\n",
    "        self.reshape = reshape\n",
    "        self.crop = crop\n",
    "        \n",
    "        # Initialize the indices (shuffle if asked)\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def alphanumeric_sort(self, l): \n",
    "        \"\"\" Sort the given iterable in the way that humans expect.\"\"\" \n",
    "        convert = lambda text: int(text) if text.isdigit() else text \n",
    "        alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "        return sorted(l, key = alphanum_key)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Number of batches per epoch : we evenly split the train set into samples\n",
    "        of size batch_size.\n",
    "        \"\"\"\n",
    "        return int(np.floor(self.X_set.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"\n",
    "        Generate one batch of data.\n",
    "        \"\"\"\n",
    "        if index >= self.__len__():\n",
    "            raise IndexError\n",
    "            \n",
    "        # Generate indices corresponding to the images in the batch\n",
    "        indices = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate the batch\n",
    "        X = self.__data_generation(indices)\n",
    "        return X\n",
    "    \n",
    "    def get_image_idx(self, im_name):\n",
    "        \"\"\"\n",
    "        Used to sort the images by an idx, when they are properly sorted (e.g. when images\n",
    "        are numbered 1 to 1000 instead of 0001 to 1000). We assume that the numerical index\n",
    "        is in the form \"XXX_tnumericalindex.tiff\" where XXC can be anything.\n",
    "        \"\"\"\n",
    "        if \"-\" in im_name.split(\".\")[0].split(\"_\")[-1][1:]:\n",
    "            return int(im_name.split(\".\")[0].split(\"_\")[-1][1:].split(\"-\")[-1][1:])\n",
    "        else:\n",
    "            return int(im_name.split(\".\")[0].split(\"_\")[-1][1:])\n",
    "        \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Updates indexes after each epoch. self.indexes is used to retrieve the\n",
    "        samples and organize them into batches.\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(self.X_set.shape[0])\n",
    "\n",
    "    def __data_generation(self, list_IDs: [int]):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples. This is where we load the\n",
    "        images if they are in a directory, and apply transformations to them.\n",
    "        \"\"\" \n",
    "        # Load data (from directory or from X_set depending on the given data)\n",
    "        if self.from_directory_X and not self.separate_directories:\n",
    "            batch_X = []\n",
    "            for im in list_IDs:\n",
    "                channels = []\n",
    "                for k in range(self.n_channels_ims):\n",
    "                    channels.append(np.expand_dims(imageio.imread(f\"{self.X_dir}/{self.X_set[im, k]}\"), axis=-1)) # add channel axis\n",
    "                batch_X.append(np.concatenate(channels, axis=-1))\n",
    "            batch_X = np.array(batch_X)    \n",
    "        elif self.from_directory_X and self.separate_directories:\n",
    "            batch_X = []\n",
    "            for im in list_IDs:\n",
    "                channels = []\n",
    "                for k in range(self.n_channels_ims):\n",
    "                    channels.append(np.expand_dims(imageio.imread(f\"{self.X_dir[k]}/{self.X_set[im, k]}\"), axis=-1)) # add channel axis\n",
    "                batch_X.append(np.concatenate(channels, axis=-1))\n",
    "            batch_X = np.array(batch_X)   \n",
    "        else:\n",
    "            batch_X = self.X_set[list_IDs]\n",
    "\n",
    "        # Preprocessing\n",
    "        if self.crop is not None:\n",
    "            batch_X = self.perf_crop(batch_X)\n",
    "            \n",
    "        if self.reshape:\n",
    "            batch_X = self.perf_reshape(batch_X)\n",
    "\n",
    "        if self.normalize:\n",
    "            batch_X = self.perf_normalize(batch_X)\n",
    "\n",
    "        return batch_X\n",
    "\n",
    "    # Preprocessing functions\n",
    "    def perf_crop(self, images):\n",
    "        crop_X = int((images.shape[1] - self.crop[0]) // 2)\n",
    "        crop_Y = int((images.shape[2] - self.crop[1]) // 2)\n",
    "        new_batch = np.empty((self.batch_size, *self.crop))\n",
    "        for i, img in enumerate(images):\n",
    "            if crop_X != 0 and crop_Y != 0:\n",
    "                new_batch[i] = img[crop_X:-crop_X, crop_Y:-crop_Y]\n",
    "            elif crop_X != 0:\n",
    "                new_batch[i] = img[crop_X:-crop_X, :]\n",
    "            elif crop_Y != 0:\n",
    "                new_batch[i] = img[:, crop_Y:-crop_Y]\n",
    "            else:\n",
    "                new_batch[i] = img\n",
    "        return new_batch\n",
    "    \n",
    "    def perf_reshape(self, images):\n",
    "        \"\"\"\n",
    "        images (np.array): batch of images of shape (batch_size, n_rows, n_cols, n_chans)\n",
    "        is_images (bool): is it a batch of images (True) or masks (False)\n",
    "        \"\"\"\n",
    "        new_batch = np.empty((self.batch_size, *self.im_size, self.n_channels_ims))\n",
    "        for i, img in enumerate(images): # the resize function normalizes the images anyways...\n",
    "            new_batch[i] = skimage.transform.resize(img, (*self.im_size, self.n_channels_ims), anti_aliasing=True)\n",
    "        return new_batch\n",
    "\n",
    "    def perf_normalize(self, images):\n",
    "        \"\"\"\n",
    "        Performs per image, per channel normalization by substracting the min and dividing by (max - min)\n",
    "        \"\"\"\n",
    "        new_batch = np.empty(images.shape)\n",
    "        for i, img in enumerate(images):\n",
    "            assert (np.min(img, axis=(0, 1)) != np.max(img, axis=(0, 1))).all(), print(\"Cannot normalize an image containing only 0 or 1 valued pixels. There is likely an empty image in the training set.\\nIf cropping was used,\"\n",
    "                                                                                       \"maybe the mask doesn't contain any white pixel in the specific region.\")\n",
    "            new_batch[i] = (img - np.min(img, axis=(0, 1))) / (np.max(img, axis=(0, 1)) - np.min(img, axis=(0, 1)))\n",
    "        return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(689, 2)\n",
      "# Batches : 689\n",
      "(1, 512, 512, 2)\n"
     ]
    }
   ],
   "source": [
    "# CHANGE DATASET PATH HERE\n",
    "test_path = [\"D:\\Hugo\\Data\\H449.1/f0_RFP\", \"D:\\Hugo\\Data\\H449.1/f0_BF\"]\n",
    "\n",
    "restrict_to = \"\"\n",
    "bat_size, nc_ims, nc_masks = 1, 2, 1 # SPECIFY HERE THE NUMBER OF CHANNELS\n",
    "crop, reshape, target_dim, normalize = None, True, (512, 512), True\n",
    "\n",
    "test_set = ImageGenerator(test_path, batch_size=bat_size, dim=target_dim, n_channels_ims=nc_ims, \n",
    "                          n_channels_masks=nc_masks, normalize=normalize, \n",
    "                          reshape=reshape, crop=crop, restrict_to=restrict_to, separate_directories=True)\n",
    "        \n",
    "def visualize_data(bf, nc_ims=1):\n",
    "#     with napari.gui_qt():\n",
    "    if nc_ims == 1:\n",
    "        viewer = napari.view_image(bf[:, :, :, :].squeeze(-1))\n",
    "    else:\n",
    "        viewer = napari.view_image(bf[:, :, :, 0])  # bf\n",
    "        for k in range(1, nc_ims):\n",
    "            viewer.add_image(bf[:, :, :, k], blending=\"additive\")\n",
    "\n",
    "plot = True\n",
    "if plot:\n",
    "    print(f\"# Batches : {len(test_set)}\")\n",
    "    bf = np.array(test_set[0])    \n",
    "    print(bf.shape)\n",
    "    visualize_data(bf, nc_ims=nc_ims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25mVak8tBmen"
   },
   "source": [
    "## Load model and perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE MODEL PATH HERE\n",
    "# os.chdir(\"D:/Hugo/Python_Scripts/Tools/unet/models\")\n",
    "\n",
    "def binary_focal_loss_fixed(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    :param y_true: A tensor of the same shape as `y_pred`\n",
    "    :param y_pred:  A tensor resulting from a sigmoid\n",
    "    :return: Output tensor.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "    epsilon = K.epsilon()\n",
    "    # Add the epsilon to prediction value\n",
    "    # y_pred = y_pred + epsilon\n",
    "    # Clip the prediciton value\n",
    "    y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "    # Calculate p_t\n",
    "    p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "    # Calculate alpha_t\n",
    "    alpha_factor = K.ones_like(y_true) * alpha\n",
    "    alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "    # Calculate cross entropy\n",
    "    cross_entropy = -K.log(p_t)\n",
    "    weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "    # Calculate focal loss\n",
    "    loss = weight * cross_entropy\n",
    "    # Sum the losses in mini_batch\n",
    "    loss = K.mean(K.sum(loss, axis=1))\n",
    "    return loss\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "    FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "    where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "    model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        # y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.mean(K.sum(loss, axis=1))\n",
    "        return loss\n",
    "    return binary_focal_loss_fixed\n",
    "\n",
    "metrics_name = \"IoU_metric\"\n",
    "def IoU_metric(y_true, y_pred):\n",
    "    threshold = tf.constant(0.5, dtype=tf.float32)\n",
    "    y_pred = K.cast(tf.math.greater(y_pred, threshold), dtype=\"float32\")\n",
    "    intersection = K.sum(y_true * y_pred, axis=(1, 2, 3))\n",
    "    union = K.sum(y_true + y_pred, axis=(1, 2, 3)) - intersection\n",
    "    return K.mean((intersection + K.epsilon()) / (union + K.epsilon()), axis=0)\n",
    "\n",
    "def jaccard_distance(smooth=50):\n",
    "\n",
    "    def jaccard_distance_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculates mean of Jaccard distance as a loss function\n",
    "        \"\"\"\n",
    "        intersection = tf.reduce_sum(y_true * y_pred, axis=(1,2))\n",
    "        sum_ = tf.reduce_sum(y_true + y_pred, axis=(1,2))\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        jd =  (1 - jac) * smooth\n",
    "        return tf.reduce_mean(jd)\n",
    "    \n",
    "    return jaccard_distance_fixed\n",
    "\n",
    "os.chdir(\"D:/Hugo/BiSeg/Models\")\n",
    "model_name = \"BS300_84ims\"\n",
    "unet = keras.models.load_model(model_name, custom_objects={\"jaccard_distance_fixed\": jaccard_distance, \"jaccard_distance\": jaccard_distance, \"IoU_metric\": IoU_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(689, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "# NOTHING TO CHANGE HERE\n",
    "# For 3-channels models\n",
    "# predictions = []\n",
    "# for im in test_set:\n",
    "#     ccc = np.concatenate([im, im, im], axis=-1)\n",
    "#     predictions.append(unet.predict(ccc))\n",
    "# predictions=np.array(predictions)\n",
    "# print(predictions.shape)\n",
    "predictions = unet.predict(test_set)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View results with Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(689, 512, 512, 2)\n"
     ]
    }
   ],
   "source": [
    "# CHANGE RFP PATH HERE\n",
    "def visualize_data_and_predictions(bf, pred, nc_ims=1, nc_masks=1):\n",
    "#     with napari.gui_qt():\n",
    "    if nc_ims == 1:\n",
    "        viewer = napari.view_image(bf[:, :, :, :].squeeze(-1))\n",
    "    else:\n",
    "        cmaps = [\"red\", \"gray\", \"blue\", \"bop purple\"]\n",
    "        viewer = napari.view_image(bf[:, :, :, 0], colormap=cmaps[0])  # bf\n",
    "        for k in range(1, nc_ims):\n",
    "            viewer.add_image(bf[:, :, :, k], blending=\"additive\", colormap=cmaps[k])\n",
    "    if nc_masks == 1:\n",
    "        viewer.add_image(pred[:, :, :, :].squeeze(-1), blending=\"additive\")\n",
    "    else:\n",
    "        cmaps = [\"red\", \"gray\", \"bop orange\", \"blue\", \"bop purple\"]\n",
    "        for k in range(0, nc_masks):\n",
    "            viewer.add_image(pred[:, :, :, k], blending=\"additive\", colormap=cmaps[k])\n",
    "\n",
    "whole_test_set = np.concatenate([test_set[i] for i in range(len(test_set))], axis=0)\n",
    "print(whole_test_set.shape)\n",
    "\n",
    "visualize_data_and_predictions(whole_test_set, predictions, nc_ims=nc_ims, nc_masks=nc_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd-dyekVZ5ZN"
   },
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "# CHANGE SAVE PATH PATH HERE\n",
    "save_path = \"D:\\Hugo\\Anaphase\\Inter_Div_Correlation/H449.1\"\n",
    "name = \"BS300.84_H449.1_f0\"\n",
    "extension = \"tif\"\n",
    "\n",
    "# Rescale image\n",
    "target_dim, nc_masks = (512, 512), 1\n",
    "\n",
    "predictions_to_save = []\n",
    "for im in predictions[:400]:\n",
    "    if target_dim != (im.shape[0], im.shape[1]):\n",
    "        if nc_masks == 1:\n",
    "            predictions_to_save.append(resize(im.squeeze(-1), target_dim, order=3)) # order = 3 :bicubic interpolation\n",
    "        else:\n",
    "            predictions_to_save.append(resize(im, target_dim, order=3))\n",
    "    else:\n",
    "        if nc_masks == 1:\n",
    "            predictions_to_save.append(im.squeeze(-1))\n",
    "        else:\n",
    "            predictions_to_save.append(im)\n",
    "predictions_to_save = np.array(predictions_to_save)\n",
    "\n",
    "if nc_masks == 1: \n",
    "    imageio.volwrite(f\"{save_path}/{name}.{extension}\", predictions_to_save)\n",
    "else:\n",
    "    channel_names = [\"mask\", \"voronoi\"]\n",
    "    for k in range(nc_masks):\n",
    "        imageio.volwrite(f\"{save_path}/{name}_{channel_names[k]}.{extension}\", predictions_to_save[:, :, :, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Perform_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
