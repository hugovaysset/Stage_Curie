{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform inference on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model, layers, models\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import Iterator, ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import Iterator, ImageDataGenerator\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import skimage.transform\n",
    "\n",
    "import napari\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Here we load the test set of Bright Field images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Generates images and masks for performing data augmentation in Keras.\n",
    "    We inherit from Sequence (instead of directly using the keras ImageDataGenerator)\n",
    "    since we want to perform augmentation on both the input image AND the mask \n",
    "    (target). This mechanism needs to be implemented in this class. This class\n",
    "    also allows to implement new augmentation transforms that are not implemented\n",
    "    in the core Keras class (illumination, etc.).\n",
    "    See : https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    and https://stackoverflow.com/questions/56758592/how-to-customize-imagedatagenerator-in-order-to-modify-the-target-variable-value\n",
    "    for more details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_set, # input images and masks\n",
    "                 n_channels_ims=1, n_channels_masks=1,\n",
    "                 batch_size: int=4, dim: tuple=(512, 512),\n",
    "                 n_channels: int=1, # informations \n",
    "                 normalize=True, reshape=False, crop=None, # preprocessing params\n",
    "                 restrict_to=\"\"): # data augmentation params\n",
    "        \"\"\"\n",
    "        X_set (list, array or str): pointer to the images (Bright-Field). If str\n",
    "        the string is assumed to be pointing at some directory.\n",
    "        Y_set (list; array or str): pointer to the masks (target). If str\n",
    "        the string is assumed to be pointing at some directory.\n",
    "        batch_size (int): size of the batch\n",
    "        dim (tuple): dimension of the images\n",
    "        n_channels (int) : number of channels of the images (1 for TIF)\n",
    "        shuffle (bool): Shuffle the dataset between each training epoch\n",
    "        normalize (bool): normalize the images and masks in the beginning\n",
    "        reshape (bool): reshape the images and masks to (dim, dim, n_channels)\n",
    "        histogram_equalization (bool): perform histogram equalization to improve\n",
    "        rendering using opencv\n",
    "        horiz_flip_percent ()\n",
    "        vert_flip_percent\n",
    "        \"\"\"\n",
    "        # super().__init__(n, batch_size, shuffle, seed)\n",
    "        self.dim = dim\n",
    "        self.im_size = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_channels_ims = n_channels_ims\n",
    "        self.n_channels_masks = n_channels_masks\n",
    "        \n",
    "        \n",
    "        self.restrict_to = restrict_to\n",
    "\n",
    "        # build the X_set in an array. If X_set is a directory containing images\n",
    "        # then self.X_set doesn't contains the images but the file names, but it\n",
    "        # is transparent for the user.\n",
    "        if type(X_set) == list:\n",
    "            self.from_directory_X = False\n",
    "            self.X_set = np.array(X_set)\n",
    "        elif type(X_set) == np.array:\n",
    "            self.from_directory_X = False\n",
    "            self.X_set = X_set           \n",
    "        elif type(X_set) == str: # assuming a path\n",
    "            self.from_directory_X = True\n",
    "            self.X_dir = X_set # path to the images dir\n",
    "            self.X_set = []\n",
    "            if self.restrict_to == \"\":\n",
    "                for k in range(0, len(os.listdir(X_set)), self.n_channels_ims):\n",
    "                    self.X_set.append(np.array(os.listdir(X_set)[k:k+self.n_channels_ims]))\n",
    "                self.X_set = np.array(self.X_set)\n",
    "            else:\n",
    "                for k in range(0, len(os.listdir(X_set)), self.n_channels_ims):\n",
    "                    if os.listdir(X_set)[k].startswith(self.restrict_to):\n",
    "                        self.X_set.append(np.array(os.listdir(X_set)[k:k+self.n_channels_ims]))\n",
    "                self.X_set = np.array(self.X_set)\n",
    "        else:\n",
    "            raise TypeError(\"X_set should be list, array or path\")\n",
    "        \n",
    "        # Preprocessing parameters\n",
    "        self.normalize = normalize\n",
    "        self.reshape = reshape\n",
    "        self.crop = crop\n",
    "        \n",
    "        # Initialize the indices (shuffle if asked)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Number of batches per epoch : we evenly split the train set into samples\n",
    "        of size batch_size.\n",
    "        \"\"\"\n",
    "        return int(np.floor(self.X_set.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"\n",
    "        Generate one batch of data.\n",
    "        \"\"\"\n",
    "        if index >= self.__len__():\n",
    "            raise IndexError\n",
    "            \n",
    "        # Generate indices corresponding to the images in the batch\n",
    "        indices = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate the batch\n",
    "        X = self.__data_generation(indices)\n",
    "        return X\n",
    "    \n",
    "    def get_image_idx(self, im_name):\n",
    "        \"\"\"\n",
    "        Used to sort the images by an idx, when they are properly sorted (e.g. when images\n",
    "        are numbered 1 to 1000 instead of 0001 to 1000). We assume that the numerical index\n",
    "        is in the form \"XXX_tnumericalindex.tiff\" where XXC can be anything.\n",
    "        \"\"\"\n",
    "        if \"-\" in im_name.split(\".\")[0].split(\"_\")[-1][1:]:\n",
    "            return int(im_name.split(\".\")[0].split(\"_\")[-1][1:].split(\"-\")[-1][1:])\n",
    "        else:\n",
    "            return int(im_name.split(\".\")[0].split(\"_\")[-1][1:])\n",
    "        \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Updates indexes after each epoch. self.indexes is used to retrieve the\n",
    "        samples and organize them into batches.\n",
    "        If shuffle : randomizes the order of the samples in order to give \n",
    "        different training batches at each epoch.\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(self.X_set.shape[0])\n",
    "\n",
    "    def __data_generation(self, list_IDs: [int]):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples. This is where we load the\n",
    "        images if they are in a directory, and apply transformations to them.\n",
    "        \"\"\" \n",
    "        # Load data (from directory or from X_set depending on the given data)\n",
    "        if self.from_directory_X:\n",
    "            batch_X = []\n",
    "            for im in list_IDs:\n",
    "                channels = []\n",
    "                for k in range(self.n_channels_ims):\n",
    "                    channels.append(np.expand_dims(imageio.imread(f\"{self.X_dir}/{self.X_set[im, k]}\"), axis=-1)) # add channel axis\n",
    "                batch_X.append(np.concatenate(channels, axis=-1))\n",
    "            batch_X = np.array(batch_X)            \n",
    "        else:\n",
    "            batch_X = self.X_set[list_IDs]\n",
    "\n",
    "        # Preprocessing\n",
    "        if self.crop is not None:\n",
    "            batch_X = self.perf_crop(batch_X)\n",
    "            \n",
    "        if self.reshape:\n",
    "            batch_X = self.perf_reshape(batch_X)\n",
    "\n",
    "        if self.normalize:\n",
    "            batch_X = self.perf_normalize(batch_X)\n",
    "\n",
    "        return batch_X\n",
    "\n",
    "    # Preprocessing functions\n",
    "    def perf_crop(self, images):\n",
    "        crop_X = int((images.shape[1] - self.crop[0]) // 2)\n",
    "        crop_Y = int((images.shape[2] - self.crop[1]) // 2)\n",
    "        new_batch = np.empty((self.batch_size, *self.crop))\n",
    "        for i, img in enumerate(images):\n",
    "            if crop_X != 0 and crop_Y != 0:\n",
    "                new_batch[i] = img[crop_X:-crop_X, crop_Y:-crop_Y]\n",
    "            elif crop_X != 0:\n",
    "                new_batch[i] = img[crop_X:-crop_X, :]\n",
    "            elif crop_Y != 0:\n",
    "                new_batch[i] = img[:, crop_Y:-crop_Y]\n",
    "            else:\n",
    "                new_batch[i] = img\n",
    "        return new_batch\n",
    "    \n",
    "    def perf_reshape(self, images):\n",
    "        \"\"\"\n",
    "        images (np.array): batch of images of shape (batch_size, n_rows, n_cols, n_chans)\n",
    "        is_images (bool): is it a batch of images (True) or masks (False)\n",
    "        \"\"\"\n",
    "        new_batch = np.empty((self.batch_size, *self.im_size, self.n_channels_ims))\n",
    "        for i, img in enumerate(images): # the resize function normalizes the images anyways...\n",
    "            new_batch[i] = skimage.transform.resize(img, (*self.im_size, self.n_channels_ims), anti_aliasing=True)\n",
    "        return new_batch\n",
    "\n",
    "    def perf_normalize(self, images):\n",
    "        \"\"\"\n",
    "        Performs per image, per channel normalization by substracting the min and dividing by (max - min)\n",
    "        \"\"\"\n",
    "        new_batch = np.empty(images.shape)\n",
    "        for i, img in enumerate(images):\n",
    "            assert (np.min(img, axis=(0, 1)) != np.max(img, axis=(0, 1))).all(), print(\"Cannot normalize an image containing only 0 or 1 valued pixels. There is likely an empty image in the training set.\\nIf cropping was used,\"\n",
    "                                                                                       \"maybe the mask doesn't contain any white pixel in the specific region.\")\n",
    "            new_batch[i] = (img - np.min(img, axis=(0, 1))) / (np.max(img, axis=(0, 1)) - np.min(img, axis=(0, 1)))\n",
    "        return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Batches : 300\n"
     ]
    }
   ],
   "source": [
    "# CHANGE DATASET PATH HERE\n",
    "test_path = \"D:\\Hugo\\Anaphase\\Inter_Div_Correlation\\BF_1-300\"\n",
    "\n",
    "restrict_to = \"\"\n",
    "bat_size, nc_ims, nc_masks = 1, 1, 2 # SPECIFY HERE THE NUMBER OF CHANNELS\n",
    "crop, reshape, target_dim, normalize = None, True, (512, 512), True\n",
    "\n",
    "test_set = ImageGenerator(test_path, batch_size=bat_size, dim=target_dim, n_channels_ims=nc_ims, \n",
    "                          n_channels_masks=nc_masks, normalize=normalize, \n",
    "                          reshape=reshape, crop=crop, restrict_to=restrict_to)\n",
    "\n",
    "def visualize_data(bf, nc_ims=1):\n",
    "    with napari.gui_qt():\n",
    "        if nc_ims == 1:\n",
    "            viewer = napari.view_image(bf[:, :, :, :].squeeze(-1))\n",
    "        else:\n",
    "            viewer = napari.view_image(bf[:, :, :, 0])  # bf\n",
    "            for k in range(1, nc_ims):\n",
    "                viewer.add_image(bf[:, :, :, k], blending=\"additive\")\n",
    "        \n",
    "plot = True\n",
    "if plot:\n",
    "    print(f\"# Batches : {len(test_set)}\")\n",
    "    bf = np.array(test_set[256])    \n",
    "    visualize_data(bf, nc_ims=nc_ims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25mVak8tBmen"
   },
   "source": [
    "## Load model and perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE MODEL PATH HERE\n",
    "# os.chdir(\"D:/Hugo/Python_Scripts/Tools/unet/models\")\n",
    "\n",
    "def binary_focal_loss_fixed(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    :param y_true: A tensor of the same shape as `y_pred`\n",
    "    :param y_pred:  A tensor resulting from a sigmoid\n",
    "    :return: Output tensor.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "    epsilon = K.epsilon()\n",
    "    # Add the epsilon to prediction value\n",
    "    # y_pred = y_pred + epsilon\n",
    "    # Clip the prediciton value\n",
    "    y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "    # Calculate p_t\n",
    "    p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "    # Calculate alpha_t\n",
    "    alpha_factor = K.ones_like(y_true) * alpha\n",
    "    alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "    # Calculate cross entropy\n",
    "    cross_entropy = -K.log(p_t)\n",
    "    weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "    # Calculate focal loss\n",
    "    loss = weight * cross_entropy\n",
    "    # Sum the losses in mini_batch\n",
    "    loss = K.mean(K.sum(loss, axis=1))\n",
    "    return loss\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "    FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "    where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "    model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        # y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.mean(K.sum(loss, axis=1))\n",
    "        return loss\n",
    "    return binary_focal_loss_fixed\n",
    "\n",
    "def jaccard_distance(smooth=50):\n",
    "\n",
    "    def jaccard_distance_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculates mean of Jaccard distance as a loss function\n",
    "        \"\"\"\n",
    "        intersection = tf.reduce_sum(y_true * y_pred, axis=(1,2))\n",
    "        sum_ = tf.reduce_sum(y_true + y_pred, axis=(1,2))\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        jd =  (1 - jac) * smooth\n",
    "        return tf.reduce_mean(jd)\n",
    "    \n",
    "    return jaccard_distance_fixed\n",
    "\n",
    "os.chdir(\"D:/Hugo/Whole_Cell/Models\")\n",
    "model_name = \"S200_voronoi\"\n",
    "unet = keras.models.load_model(model_name, custom_objects={\"jaccard_distance_fixed\": jaccard_distance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTHING TO CHANGE HERE\n",
    "# For 3-channels models\n",
    "predictions = unet.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View results with Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "# CHANGE RFP PATH HERE\n",
    "def visualize_data_and_predictions(bf, pred, nc_ims=1, nc_masks=1):\n",
    "    with napari.gui_qt():\n",
    "        if nc_ims == 1:\n",
    "            viewer = napari.view_image(bf[:, :, :, :].squeeze(-1))\n",
    "        else:\n",
    "            viewer = napari.view_image(bf[:, :, :, 0])  # bf\n",
    "            for k in range(1, nc_ims):\n",
    "                viewer.add_image(bf[:, :, :, k], blending=\"additive\")\n",
    "        if nc_masks == 1:\n",
    "            viewer.add_image(pred[:, :, :, :].squeeze(-1), blending=\"additive\")\n",
    "        else:\n",
    "            cmaps = [\"bop blue\", \"red\", \"bop_orange\", \"blue\", \"bop purple\"]\n",
    "            for k in range(0, nc_masks):\n",
    "                viewer.add_image(pred[:, :, :, k], blending=\"additive\", colormap=cmaps[k])\n",
    "\n",
    "whole_test_set = np.concatenate([test_set[i] for i in range(len(test_set))], axis=0)\n",
    "print(whole_test_set.shape)\n",
    "\n",
    "visualize_data_and_predictions(whole_test_set, predictions, nc_ims=nc_ims, nc_masks=nc_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd-dyekVZ5ZN"
   },
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot select an axis to squeeze out which has size not equal to one",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-04e1861d4cd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnc_masks\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mpredictions_to_save\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mpredictions_to_save\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot select an axis to squeeze out which has size not equal to one"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "# CHANGE SAVE PATH PATH HERE\n",
    "save_path = \"D:/Hugo/Anaphase/Inter_Div_Correlation/\"\n",
    "name = \"S-Voronoi_H449_pos2_1-300\"\n",
    "extension = \"tif\"\n",
    "\n",
    "# Rescale image\n",
    "target_dim, nc_masks = (512, 512), 2\n",
    "\n",
    "predictions_to_save = []\n",
    "for im in predictions:\n",
    "    if target_dim != (im.shape[0], im.shape[1]):\n",
    "        if nc_masks == 1:\n",
    "            predictions_to_save.append(resize(im.squeeze(-1), target_dim, order=3)) # order = 3 :bicubic interpolation\n",
    "        else:\n",
    "            predictions_to_save.append(resize(im, target_dim, order=3))\n",
    "    else:\n",
    "        if nc_masks == 1:\n",
    "            predictions_to_save.append(im.squeeze(-1))\n",
    "        else:\n",
    "            predictions_to_save.append(im)\n",
    "predictions_to_save = np.array(predictions_to_save)\n",
    "\n",
    "if nc_masks == 1: \n",
    "    imageio.volwrite(f\"{save_path}/{name}.{extension}\", predictions_to_save)\n",
    "else:\n",
    "    channel_names = [\"mask\", \"voronoi\"]\n",
    "    for k in range(nc_masks):\n",
    "        imageio.volwrite(f\"{save_path}/{name}_{channel_names[k]}.{extension}\", predictions_to_save[:, :, :, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Perform_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
