{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaKMuBSZ9-aD"
   },
   "source": [
    "# Train a U-Net Model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIllmxrJHWvA"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model, layers, models\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import Iterator, ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import Iterator, ImageDataGenerator\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_built_with_cuda()) \n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "import skimage.transform\n",
    "\n",
    "import napari\n",
    "\n",
    "# tf.config.gpu.set_per_process_memory_fraction(0.75)\n",
    "# tf.config.gpu.set_per_process_memory_growth(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMaskGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Generates images and masks for performing data augmentation in Keras.\n",
    "    We inherit from Sequence (instead of directly using the keras ImageDataGenerator)\n",
    "    since we want to perform augmentation on both the input image AND the mask \n",
    "    (target). This mechanism needs to be implemented in this class. This class\n",
    "    also allows to implement new augmentation transforms that are not implemented\n",
    "    in the core Keras class (illumination, etc.).\n",
    "    See : https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    and https://stackoverflow.com/questions/56758592/how-to-customize-imagedatagenerator-in-order-to-modify-the-target-variable-value\n",
    "    for more details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_set, Y_set=None, # input images and masks\n",
    "                 batch_size: int=32, dim: tuple=(512, 512),\n",
    "                 n_channels_ims: int=1, n_channels_masks: int=1, # informations \n",
    "                 shuffle: bool=True, normalize_ims=True, normalize_masks=False, reshape=False, crop=None,# preprocessing params\n",
    "                 **kwargs): # data augmentation params\n",
    "        \"\"\"\n",
    "        X_set (list, array or str): pointer to the images (Bright-Field). If str\n",
    "        the string is assumed to be pointing at some directory.\n",
    "        Y_set (list; array or str): pointer to the masks (target). If str\n",
    "        the string is assumed to be pointing at some directory.\n",
    "        batch_size (int): size of the batch\n",
    "        dim (tuple): dimension of the images\n",
    "        n_channels_ims (int) : number of channels of the images (1 for TIF)\n",
    "        shuffle (bool): Shuffle the dataset between each training epoch\n",
    "        crop (tuple): Target dim of one image after cropping\n",
    "        normalize (bool): normalize the images and masks in the beginning\n",
    "        reshape (bool): reshape the images and masks to (dim, dim, n_channels_ims)\n",
    "        histogram_equalization (bool): perform histogram equalization to improve\n",
    "        rendering using opencv\n",
    "        horiz_flip_percent ()\n",
    "        vert_flip_percent\n",
    "        \"\"\"\n",
    "        # super().__init__(n, batch_size, shuffle, seed)\n",
    "        self.dim = dim\n",
    "        self.im_size = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels_ims = n_channels_ims\n",
    "        self.n_channels_masks = n_channels_masks\n",
    "        \n",
    "        # build the X_set in an array. If X_set is a directory containing images\n",
    "        # then self.X_set doesn't contains the images but the file names, but it\n",
    "        # is transparent for the user.\n",
    "        if type(X_set) == list:\n",
    "            self.from_directory_X = False\n",
    "            self.X_set = np.array(X_set)\n",
    "        elif type(X_set) == np.array:\n",
    "            self.from_directory_X = False\n",
    "            self.X_set = X_set\n",
    "        elif type(X_set) == str: # assuming a path\n",
    "            self.from_directory_X = True\n",
    "            self.X_dir = X_set # path to the images dir\n",
    "#             if self.n_channels_ims == 1:\n",
    "#                 self.X_set = np.array(sorted(os.listdir(X_set))) # sorted guarantees the order\n",
    "#             else: # n_channels_ims > 1 : several channels per image\n",
    "            self.X_set = []\n",
    "            for k in range(0, len(os.listdir(X_set)), self.n_channels_ims):\n",
    "                self.X_set.append(np.array(os.listdir(X_set)[k:k+self.n_channels_ims]))\n",
    "            self.X_set = np.array(self.X_set)\n",
    "        else:\n",
    "            raise TypeError(\"X_set should be list, array or path\")\n",
    "        \n",
    "        # build the Y_set in an array\n",
    "        if type(Y_set) == list:\n",
    "            self.from_directory_Y = False\n",
    "            self.Y_set = np.array(Y_set)\n",
    "        elif type(Y_set) == np.array:\n",
    "            self.from_directory_Y = False\n",
    "            self.Y_set = Y_set\n",
    "        elif type(Y_set) == str: # assuming a path\n",
    "            self.from_directory_Y = True\n",
    "            self.Y_dir = Y_set # path to the masks dir\n",
    "            self.Y_set = []\n",
    "            for k in range(0, len(os.listdir(Y_set)), self.n_channels_masks):\n",
    "                self.Y_set.append(np.array(os.listdir(Y_set)[k:k+self.n_channels_masks]))\n",
    "            self.Y_set = np.array(self.Y_set)\n",
    "        else:\n",
    "            raise TypeError(\"Y_set should be list, array or path\")\n",
    "\n",
    "        # Check if there are the same number of images in X (images) and Y (masks)\n",
    "        assert self.X_set.shape[0] != 0 and self.Y_set.shape[0] != 0, print(f\"Directory '{X_set}' is empty!\")\n",
    "        assert self.X_set.shape[0] == self.Y_set.shape[0], print(f\"{self.X_set.shape[0]} images != {self.Y_set.shape[0]} masks\")\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Preprocessing parameters\n",
    "        self.normalize_ims = normalize_ims\n",
    "        self.normalize_masks = normalize_masks\n",
    "        self.reshape = reshape\n",
    "        self.crop = crop\n",
    "\n",
    "        # The Keras generator that will be used to perform data augmentation \n",
    "        self.generator = ImageDataGenerator(**kwargs)\n",
    "\n",
    "        # Initialize the indices (shuffle if asked)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Number of batches per epoch : we evenly split the train set into samples\n",
    "        of size batch_size.\n",
    "        \"\"\"\n",
    "        return int(np.floor(self.X_set.shape[0] / self.batch_size))\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"\n",
    "        Generate one batch of data.\n",
    "        \"\"\"\n",
    "        if index >= self.__len__():\n",
    "            raise IndexError\n",
    "        \n",
    "        # Generate indices corresponding to the images in the batch\n",
    "        indices = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate the batch\n",
    "        X, Y = self.__data_generation(indices)\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Updates indexes after each epoch. self.indexes is used to retrieve the\n",
    "        samples and organize them into batches.\n",
    "        If shuffle : randomizes the order of the samples in order to give \n",
    "        different training batches at each epoch.\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(self.X_set.shape[0])\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs: [int]):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples. This is where we load the\n",
    "        images if they are in a directory, and apply transformations to them.\n",
    "        \"\"\" \n",
    "        # Load data (from directory or from X_set depending on the given data)\n",
    "        if self.from_directory_X:\n",
    "            batch_X = []\n",
    "            for im in list_IDs:\n",
    "                channels = []\n",
    "                for k in range(self.n_channels_ims):\n",
    "                    channels.append(np.expand_dims(imageio.imread(f\"{self.X_dir}/{self.X_set[im, k]}\"), axis=-1)) # add channel axis\n",
    "                batch_X.append(np.concatenate(channels, axis=-1))\n",
    "            batch_X = np.array(batch_X)\n",
    "        else:\n",
    "            batch_X = self.X_set[list_IDs]\n",
    "\n",
    "        if self.from_directory_Y:\n",
    "            batch_Y = []\n",
    "            for im in list_IDs:\n",
    "                channels = []\n",
    "                for k in range(self.n_channels_masks):\n",
    "                    channels.append(np.expand_dims(imageio.imread(f\"{self.Y_dir}/{self.Y_set[im, k]}\"), axis=-1)) # add channel axis\n",
    "                batch_Y.append(np.concatenate(channels, axis=-1))\n",
    "            batch_Y = np.array(batch_Y) \n",
    "        else:\n",
    "            batch_Y = self.Y_set[list_IDs]\n",
    "\n",
    "        # Preprocessing\n",
    "        if self.crop is not None:\n",
    "            batch_X = self.perf_crop(batch_X)\n",
    "            batch_Y = self.perf_crop(batch_Y)\n",
    "\n",
    "        if self.reshape:\n",
    "            batch_X = self.perf_reshape(batch_X, is_images=True)\n",
    "            batch_Y = self.perf_reshape(batch_Y, is_images=False)\n",
    "\n",
    "        if self.normalize_ims:\n",
    "            batch_X = self.perf_normalize(batch_X)\n",
    "        if self.normalize_masks:\n",
    "            batch_Y = self.perf_normalize(batch_Y)\n",
    "\n",
    "#         if self.n_channels_ims == 3:\n",
    "#             batch_X = np.concatenate([batch_X, batch_X, batch_X], axis=-1)\n",
    "\n",
    "        # Perform the SAME transformation on the image and on the mask\n",
    "        for i, (img, mask) in enumerate(zip(batch_X, batch_Y)):\n",
    "            transform_params = self.generator.get_random_transform(img.shape)\n",
    "            batch_X[i] = self.generator.apply_transform(img, transform_params)\n",
    "            batch_Y[i] = self.generator.apply_transform(mask, transform_params)\n",
    "            \n",
    "        return batch_X, batch_Y        \n",
    "\n",
    "    # Preprocessing functions\n",
    "    def perf_crop(self, images):\n",
    "        crop_X = int((images.shape[1] - self.crop[0]) // 2)\n",
    "        crop_Y = int((images.shape[2] - self.crop[1]) // 2)\n",
    "        assert (crop_X >= 0 and crop_Y >= 0), print(f\"Target size after cropping {self.crop} should be lower than the initial shape {(images.shape[1], images.shape[2])}.\")\n",
    "        new_batch = np.empty((self.batch_size, *self.crop, images.shape[3]))\n",
    "        for i, img in enumerate(images):\n",
    "            if crop_X != 0 and crop_Y != 0:\n",
    "                new_batch[i] = img[crop_X:-crop_X, crop_Y:-crop_Y]\n",
    "            elif crop_X != 0:\n",
    "                new_batch[i] = img[crop_X:-crop_X, :]\n",
    "            elif crop_Y != 0:\n",
    "                new_batch[i] = img[:, crop_Y:-crop_Y]\n",
    "            else:\n",
    "                new_batch[i] = img\n",
    "        return new_batch\n",
    "\n",
    "    def perf_reshape(self, images, is_images=True):\n",
    "        \"\"\"\n",
    "        images (np.array): batch of images of shape (batch_size, n_rows, n_cols, n_chans)\n",
    "        is_images (bool): is it a batch of images (True) or masks (False)\n",
    "        \"\"\"\n",
    "        if is_images:  # batch of images\n",
    "            new_batch = np.empty((self.batch_size, *self.im_size, self.n_channels_ims))\n",
    "            for i, img in enumerate(images): # the resize function normalizes the images anyways...\n",
    "                new_batch[i] = skimage.transform.resize(img, (*self.im_size, self.n_channels_ims), anti_aliasing=True)\n",
    "        else:  # batch of masks\n",
    "            new_batch = np.empty((self.batch_size, *self.im_size, self.n_channels_masks))\n",
    "            for i, img in enumerate(images):\n",
    "                new_batch[i] = skimage.transform.resize(img, (*self.im_size, self.n_channels_masks), anti_aliasing=True)\n",
    "        return new_batch\n",
    "\n",
    "    def perf_normalize(self, images):\n",
    "        \"\"\"\n",
    "        Performs per image, per channel normalization by substracting the min and dividing by (max - min)\n",
    "        \"\"\"\n",
    "        new_batch = np.empty(images.shape)\n",
    "        for i, img in enumerate(images):\n",
    "            assert (np.min(img, axis=(0, 1)) != np.max(img, axis=(0, 1))).all(), print(\"Cannot normalize an image containing only 0 or 1 valued pixels. There is likely an empty image in the training set.\\nIf cropping was used,\"\n",
    "                                                                                       \"maybe the mask doesn't contain any white pixel in the specific region.\")\n",
    "            new_batch[i] = (img - np.min(img, axis=(0, 1))) / (np.max(img, axis=(0, 1)) - np.min(img, axis=(0, 1)))\n",
    "        return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 4\n",
      "# Channels images: 1, # Channels masks: 2\n",
      "Cropping : None, Target shape: True\n",
      "Normalize images: True, Normalize masks: True.\n"
     ]
    }
   ],
   "source": [
    "data_path = \"D:/Hugo/Whole_Cell/Train_Set\"\n",
    "bf_dir, mask_dir = f\"{data_path}/images/\", f\"{data_path}/masks_voronoi/\"\n",
    "\n",
    "# cf. la doc Keras pour voir tout ce qu'il est possible de faire\n",
    "# https://keras.io/api/preprocessing/image/\n",
    "# voir aussi la librairie imgaug ou albumentation pour implementer de nouvelles transfo\n",
    "augmentation_params = dict(zoom_range=[0.9, 1.5],\n",
    "                           rotation_range=360,\n",
    "                           height_shift_range=0.2,\n",
    "                           width_shift_range=0.2,\n",
    "                           fill_mode=\"constant\", cval=0)\n",
    "\n",
    "val_augmentation_params = {}\n",
    "\n",
    "# augmentation_params = {}\n",
    "\n",
    "bat_size, nc_ims, nc_masks, shuffle = 4, 1, 2, True  # SPECIFY HERE THE NUMBER OF CHANNELS\n",
    "crop, reshape, target_dim, normalize_ims, normalize_masks = None, True, (512, 512), True, True\n",
    "\n",
    "print(f\"Batch size: {bat_size}\")\n",
    "print(f\"# Channels images: {nc_ims}, # Channels masks: {nc_masks}\")\n",
    "print(f\"Cropping : {crop}, Target shape: {reshape}\")\n",
    "print(f\"Normalize images: {normalize_ims}, Normalize masks: {normalize_masks}.\")\n",
    "\n",
    "generator = ImageMaskGenerator(bf_dir, mask_dir, \n",
    "                               batch_size=bat_size, dim=target_dim, n_channels_ims=nc_ims, n_channels_masks=nc_masks, \n",
    "                               shuffle=shuffle, normalize_ims=normalize_ims, normalize_masks=normalize_masks, reshape=reshape, crop=crop,\n",
    "                                **augmentation_params)\n",
    "\n",
    "val_generator = ImageMaskGenerator(f\"{data_path}/val_images/\", f\"{data_path}/val_masks_voronoi/\", \n",
    "                               batch_size=1, dim=target_dim, n_channels_ims=nc_ims, n_channels_masks=nc_masks,\n",
    "                               shuffle=shuffle, normalize_ims=normalize_ims, normalize_masks=normalize_masks, reshape=reshape, crop=crop,\n",
    "                                **val_augmentation_params)\n",
    "\n",
    "def visualize_data(bf, masks, nc_ims=1, nc_masks=1):\n",
    "    with napari.gui_qt():\n",
    "        if nc_ims == 1:\n",
    "            viewer = napari.view_image(bf[:, :, :, :].squeeze(-1))\n",
    "        else:\n",
    "            viewer = napari.view_image(bf[:, :, :, 0])  # bf\n",
    "            for k in range(1, nc_ims):\n",
    "                viewer.add_image(bf[:, :, :, k], blending=\"additive\")\n",
    "        if nc_masks == 1:    \n",
    "            viewer.add_image(masks[:, :, :, :].squeeze(-1), blending=\"additive\")\n",
    "        else:\n",
    "            for k in range(0, nc_masks):\n",
    "                viewer.add_image(masks[:, :, :, k], blending=\"additive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Batches : 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-97e3c297d91a>:145: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  batch_X = np.array(batch_X)\n"
     ]
    }
   ],
   "source": [
    "plot = True\n",
    "if plot:\n",
    "    print(f\"# Batches : {len(generator)}\")\n",
    "    bf, masks = generator[4]\n",
    "    bf, masks = np.array(bf), np.array(masks)\n",
    "    \n",
    "    visualize_data(bf, masks, nc_ims=nc_ims, nc_masks=nc_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YbX33TwJ6S_"
   },
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(nbr, x, y, n_channels_imgs=1, n_channels_masks=1, final_activation=\"sigmoid\"):\n",
    "    \"\"\"\n",
    "    nbr (int): kernel side\n",
    "    x (int): image height\n",
    "    y (int): image width\n",
    "    \"\"\"\n",
    "    print(f\"# input channels : {n_channels_imgs}.\")\n",
    "    print(f\"# output channels : {n_channels_masks}.\")\n",
    "    \n",
    "    initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "    entree=layers.Input(shape=(x, y, n_channels_imgs), dtype='float16')\n",
    "\n",
    "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(entree)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result1=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.MaxPool2D()(result1)\n",
    "\n",
    "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result2=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.MaxPool2D()(result2)\n",
    "\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result3=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.MaxPool2D()(result3)\n",
    "\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result4=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.MaxPool2D()(result4)\n",
    "\n",
    "    result=layers.Conv2D(8*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.UpSampling2D()(result)\n",
    "    result=tf.concat([result, result4], axis=3)\n",
    "\n",
    "    result=layers.Conv2D(8*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.UpSampling2D()(result)\n",
    "    result=tf.concat([result, result3], axis=3)\n",
    "\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.UpSampling2D()(result)\n",
    "    result=tf.concat([result, result2], axis=3)\n",
    "\n",
    "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.UpSampling2D()(result)\n",
    "    result=tf.concat([result, result1], axis=3)\n",
    "\n",
    "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "\n",
    "    sortie=layers.Conv2D(n_channels_masks, 1, activation=final_activation, padding='same', kernel_initializer=initializer)(result)\n",
    "\n",
    "    model=models.Model(inputs=entree, outputs=sortie)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtOkjG_hrRsl"
   },
   "source": [
    "## Loss function : Weighted binary crossentropy\r\n",
    "\r\n",
    "This step is important because we are facing a class imbalance problem : the 0 class (i.e. background) are way more numerous than the 1 class (i.e. yeast pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary for whole cells\n",
    "# TODO: try it on mating or buds\n",
    "\n",
    "class WeightedBinaryCrossEntropy():\n",
    "\n",
    "    def __init__(self, class_weight={0: 0.5, 1: 0.5}):\n",
    "        self.class_weight = class_weight\n",
    "        self.__name__ = \"binary_cross_entropy\"\n",
    "\n",
    "    def __call__(self, Y_true, Y_pred):\n",
    "        \"\"\"\n",
    "        Compute the weights binary cross entropy for a given mask Y_true and a given\n",
    "        prediction Y_pred.\n",
    "        \"\"\"\n",
    "        sample_weight = {0: 0.2, 1: 0.8}\n",
    "        y_true = K.clip(Y_true, K.epsilon(), 1-K.epsilon())\n",
    "        y_pred = K.clip(Y_pred, K.epsilon(), 1-K.epsilon())\n",
    "        logloss = -(y_true * K.log(y_pred) * self.class_weight[1] \n",
    "                    + (1 - y_true) * K.log(1 - y_pred) * self.class_weight[0] )\n",
    "        return K.mean(logloss, axis=-1)\n",
    "\n",
    "weights = {0: 1, 1: 100}\n",
    "binary_cross_entropy = WeightedBinaryCrossEntropy(class_weight=weights)\n",
    "\n",
    "def jaccard_distance(smooth=20):\n",
    "\n",
    "    def jaccard_distance_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculates mean of Jaccard distance as a loss function\n",
    "        \"\"\"\n",
    "        intersection = tf.reduce_sum(y_true * y_pred, axis=(1,2))\n",
    "        sum_ = tf.reduce_sum(y_true + y_pred, axis=(1,2))\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        jd =  (1 - jac) * smooth\n",
    "        return tf.reduce_mean(jd)\n",
    "    \n",
    "    return jaccard_distance_fixed\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "    FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "    where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "    model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        # y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.mean(K.sum(loss, axis=1))\n",
    "        return loss\n",
    "    return binary_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ik4CeRhs1v9J"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss : <function jaccard_distance.<locals>.jaccard_distance_fixed at 0x0000024A76023C10>.\n",
      "Smoothing : 50\n",
      "# input channels : 1.\n",
      "# output channels : 2.\n",
      "WARNING:tensorflow:Layer conv2d_38 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-97e3c297d91a>:145: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  batch_X = np.array(batch_X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "26/26 [==============================] - 34s 1s/step - loss: 36.4303 - mean_IoU: 0.5987 - val_loss: 44.1119 - val_mean_IoU: 0.5108 - lr: 0.0050\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 33s 1s/step - loss: 28.0993 - mean_IoU: 0.6591 - val_loss: 49.5424 - val_mean_IoU: 0.4240 - lr: 0.0050\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 26.9159 - mean_IoU: 0.6932 - val_loss: 48.2842 - val_mean_IoU: 0.4234 - lr: 0.0050\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 22.5867 - mean_IoU: 0.8112 - val_loss: 46.6282 - val_mean_IoU: 0.4349 - lr: 0.0050\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 18.3490 - mean_IoU: 0.8780 - val_loss: 47.0437 - val_mean_IoU: 0.4238 - lr: 0.0050\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 17.6855 - mean_IoU: 0.8806 - val_loss: 42.6772 - val_mean_IoU: 0.4596 - lr: 0.0050\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 17.2613 - mean_IoU: 0.8872 - val_loss: 41.5717 - val_mean_IoU: 0.4621 - lr: 0.0050\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 17.0050 - mean_IoU: 0.8867 - val_loss: 42.6145 - val_mean_IoU: 0.4712 - lr: 0.0050\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 16.8673 - mean_IoU: 0.8872 - val_loss: 45.8619 - val_mean_IoU: 0.4435 - lr: 0.0050\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 16.7269 - mean_IoU: 0.8862 - val_loss: 32.5259 - val_mean_IoU: 0.5535 - lr: 0.0050\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 16.4431 - mean_IoU: 0.8890 - val_loss: 33.6053 - val_mean_IoU: 0.5593 - lr: 0.0050\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 16.4632 - mean_IoU: 0.8897 - val_loss: 32.2037 - val_mean_IoU: 0.5958 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 16.3776 - mean_IoU: 0.8877 - val_loss: 23.7381 - val_mean_IoU: 0.6944 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 16.3252 - mean_IoU: 0.8901 - val_loss: 24.7919 - val_mean_IoU: 0.6629 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 16.2322 - mean_IoU: 0.8892 - val_loss: 23.2680 - val_mean_IoU: 0.6441 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 16.0838 - mean_IoU: 0.8889 - val_loss: 22.2478 - val_mean_IoU: 0.6590 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 16.1797 - mean_IoU: 0.8877 - val_loss: 25.0167 - val_mean_IoU: 0.6254 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 16.2071 - mean_IoU: 0.8859 - val_loss: 20.8295 - val_mean_IoU: 0.7519 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 16.0208 - mean_IoU: 0.8879 - val_loss: 19.6612 - val_mean_IoU: 0.7595 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 16.0533 - mean_IoU: 0.8847 - val_loss: 19.4834 - val_mean_IoU: 0.7554 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 16.0849 - mean_IoU: 0.8859 - val_loss: 19.9274 - val_mean_IoU: 0.7761 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 16.0170 - mean_IoU: 0.8856 - val_loss: 20.3429 - val_mean_IoU: 0.7771 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.9543 - mean_IoU: 0.8858 - val_loss: 20.0788 - val_mean_IoU: 0.7693 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.9459 - mean_IoU: 0.8856 - val_loss: 20.3899 - val_mean_IoU: 0.7759 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.9128 - mean_IoU: 0.8858 - val_loss: 20.4668 - val_mean_IoU: 0.7769 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.8928 - mean_IoU: 0.8846 - val_loss: 20.3050 - val_mean_IoU: 0.7789 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.9020 - mean_IoU: 0.8847 - val_loss: 20.8154 - val_mean_IoU: 0.7740 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.9737 - mean_IoU: 0.8835 - val_loss: 21.5602 - val_mean_IoU: 0.7618 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.9044 - mean_IoU: 0.8845 - val_loss: 20.6249 - val_mean_IoU: 0.7588 - lr: 0.0050\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.8952 - mean_IoU: 0.8852 - val_loss: 19.8628 - val_mean_IoU: 0.7763 - lr: 0.0050\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.8258 - mean_IoU: 0.8837 - val_loss: 20.2487 - val_mean_IoU: 0.7810 - lr: 0.0050\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.8573 - mean_IoU: 0.8822 - val_loss: 19.6911 - val_mean_IoU: 0.7666 - lr: 0.0050\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.8564 - mean_IoU: 0.8844 - val_loss: 19.8294 - val_mean_IoU: 0.7692 - lr: 0.0050\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.8521 - mean_IoU: 0.8834 - val_loss: 20.4950 - val_mean_IoU: 0.7705 - lr: 0.0050\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.7920 - mean_IoU: 0.8825 - val_loss: 19.9656 - val_mean_IoU: 0.7837 - lr: 0.0050\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.8215 - mean_IoU: 0.8830 - val_loss: 19.5263 - val_mean_IoU: 0.7769 - lr: 0.0050\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.8032 - mean_IoU: 0.8816 - val_loss: 20.4591 - val_mean_IoU: 0.7783 - lr: 0.0050\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.7852 - mean_IoU: 0.8825 - val_loss: 20.8387 - val_mean_IoU: 0.7698 - lr: 0.0050\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.7954 - mean_IoU: 0.8813 - val_loss: 19.9550 - val_mean_IoU: 0.7632 - lr: 0.0050\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.7405 - mean_IoU: 0.8812 - val_loss: 20.5492 - val_mean_IoU: 0.7642 - lr: 0.0050\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.7423 - mean_IoU: 0.8817 - val_loss: 20.1111 - val_mean_IoU: 0.7747 - lr: 0.0050\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.7357 - mean_IoU: 0.8823 - val_loss: 20.1595 - val_mean_IoU: 0.7784 - lr: 0.0050\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.7532 - mean_IoU: 0.8796 - val_loss: 20.6632 - val_mean_IoU: 0.7703 - lr: 0.0050\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.7336 - mean_IoU: 0.8799 - val_loss: 19.5995 - val_mean_IoU: 0.7822 - lr: 0.0050\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.7241 - mean_IoU: 0.8790 - val_loss: 19.5726 - val_mean_IoU: 0.7842 - lr: 0.0050\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.6077 - mean_IoU: 0.8803 - val_loss: 19.7298 - val_mean_IoU: 0.7840 - lr: 0.0050\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.7450 - mean_IoU: 0.8772 - val_loss: 21.7245 - val_mean_IoU: 0.7754 - lr: 0.0050\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.7669 - mean_IoU: 0.8796 - val_loss: 20.3192 - val_mean_IoU: 0.7785 - lr: 0.0050\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.6777 - mean_IoU: 0.8791 - val_loss: 20.6465 - val_mean_IoU: 0.7782 - lr: 0.0050\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.6533 - mean_IoU: 0.8793 - val_loss: 19.5504 - val_mean_IoU: 0.7764 - lr: 0.0050\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.6578 - mean_IoU: 0.8784 - val_loss: 20.5673 - val_mean_IoU: 0.7780 - lr: 0.0050\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.7060 - mean_IoU: 0.8774 - val_loss: 19.9132 - val_mean_IoU: 0.7630 - lr: 0.0050\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5988 - mean_IoU: 0.8790 - val_loss: 20.6220 - val_mean_IoU: 0.7808 - lr: 0.0050\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5373 - mean_IoU: 0.8797 - val_loss: 19.8173 - val_mean_IoU: 0.7752 - lr: 0.0050\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.6190 - mean_IoU: 0.8799 - val_loss: 19.7378 - val_mean_IoU: 0.7780 - lr: 0.0050\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5529 - mean_IoU: 0.8797 - val_loss: 20.0575 - val_mean_IoU: 0.7803 - lr: 0.0050\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.6530 - mean_IoU: 0.8788 - val_loss: 20.3469 - val_mean_IoU: 0.7790 - lr: 0.0050\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.6340 - mean_IoU: 0.8782 - val_loss: 19.5099 - val_mean_IoU: 0.7836 - lr: 0.0050\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5352 - mean_IoU: 0.8784 - val_loss: 19.6259 - val_mean_IoU: 0.7821 - lr: 0.0050\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5951 - mean_IoU: 0.8795 - val_loss: 21.4070 - val_mean_IoU: 0.7804 - lr: 0.0050\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.6612 - mean_IoU: 0.8792 - val_loss: 20.8874 - val_mean_IoU: 0.7729 - lr: 0.0050\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 15.5318 - mean_IoU: 0.8787 - val_loss: 19.8962 - val_mean_IoU: 0.7748 - lr: 0.0050\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5634 - mean_IoU: 0.8783 - val_loss: 20.1450 - val_mean_IoU: 0.7873 - lr: 0.0050\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5505 - mean_IoU: 0.8788 - val_loss: 20.2917 - val_mean_IoU: 0.7790 - lr: 0.0050\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.6407 - mean_IoU: 0.8770 - val_loss: 20.3221 - val_mean_IoU: 0.7723 - lr: 0.0050\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5891 - mean_IoU: 0.8799 - val_loss: 20.3371 - val_mean_IoU: 0.7826 - lr: 0.0050\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5484 - mean_IoU: 0.8786 - val_loss: 20.7141 - val_mean_IoU: 0.7773 - lr: 0.0050\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5831 - mean_IoU: 0.8769 - val_loss: 20.4156 - val_mean_IoU: 0.7766 - lr: 0.0050\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5383 - mean_IoU: 0.8774 - val_loss: 19.9135 - val_mean_IoU: 0.7699 - lr: 0.0050\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.5627 - mean_IoU: 0.8782 - val_loss: 20.5646 - val_mean_IoU: 0.7720 - lr: 0.0050\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.6419 - mean_IoU: 0.8758 - val_loss: 20.2515 - val_mean_IoU: 0.7779 - lr: 0.0050\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - ETA: 0s - loss: 15.5518 - mean_IoU: 0.8758\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.5518 - mean_IoU: 0.8758 - val_loss: 20.4430 - val_mean_IoU: 0.7806 - lr: 0.0050\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.4998 - mean_IoU: 0.8774 - val_loss: 19.3232 - val_mean_IoU: 0.7810 - lr: 0.0025\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.4155 - mean_IoU: 0.8771 - val_loss: 19.0643 - val_mean_IoU: 0.7818 - lr: 0.0025\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3737 - mean_IoU: 0.8781 - val_loss: 19.8561 - val_mean_IoU: 0.7794 - lr: 0.0025\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.4521 - mean_IoU: 0.8788 - val_loss: 20.3704 - val_mean_IoU: 0.7781 - lr: 0.0025\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3727 - mean_IoU: 0.8793 - val_loss: 19.6222 - val_mean_IoU: 0.7803 - lr: 0.0025\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3345 - mean_IoU: 0.8787 - val_loss: 19.7678 - val_mean_IoU: 0.7796 - lr: 0.0025\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3772 - mean_IoU: 0.8785 - val_loss: 19.6301 - val_mean_IoU: 0.7799 - lr: 0.0025\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.3441 - mean_IoU: 0.8765 - val_loss: 19.8343 - val_mean_IoU: 0.7800 - lr: 0.0025\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3386 - mean_IoU: 0.8784 - val_loss: 19.7146 - val_mean_IoU: 0.7823 - lr: 0.0025\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.4026 - mean_IoU: 0.8777 - val_loss: 19.3967 - val_mean_IoU: 0.7759 - lr: 0.0025\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3556 - mean_IoU: 0.8793 - val_loss: 19.7463 - val_mean_IoU: 0.7721 - lr: 0.0025\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.4196 - mean_IoU: 0.8778 - val_loss: 19.5620 - val_mean_IoU: 0.7811 - lr: 0.0025\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.3433 - mean_IoU: 0.8781 - val_loss: 20.1987 - val_mean_IoU: 0.7817 - lr: 0.0025\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3754 - mean_IoU: 0.8772 - val_loss: 20.0412 - val_mean_IoU: 0.7795 - lr: 0.0025\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.3909 - mean_IoU: 0.8781 - val_loss: 19.7437 - val_mean_IoU: 0.7812 - lr: 0.0025\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - ETA: 0s - loss: 15.3575 - mean_IoU: 0.8779\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.3575 - mean_IoU: 0.8779 - val_loss: 19.9054 - val_mean_IoU: 0.7785 - lr: 0.0025\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.3815 - mean_IoU: 0.8777 - val_loss: 19.9061 - val_mean_IoU: 0.7798 - lr: 0.0012\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3387 - mean_IoU: 0.8792 - val_loss: 19.7548 - val_mean_IoU: 0.7822 - lr: 0.0012\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3266 - mean_IoU: 0.8785 - val_loss: 20.1598 - val_mean_IoU: 0.7822 - lr: 0.0012\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2874 - mean_IoU: 0.8786 - val_loss: 19.8087 - val_mean_IoU: 0.7832 - lr: 0.0012\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3148 - mean_IoU: 0.8794 - val_loss: 19.8965 - val_mean_IoU: 0.7831 - lr: 0.0012\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.3429 - mean_IoU: 0.8785 - val_loss: 19.8758 - val_mean_IoU: 0.7818 - lr: 0.0012\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2798 - mean_IoU: 0.8785 - val_loss: 19.2695 - val_mean_IoU: 0.7794 - lr: 0.0012\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3534 - mean_IoU: 0.8777 - val_loss: 19.8715 - val_mean_IoU: 0.7854 - lr: 0.0012\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2716 - mean_IoU: 0.8777 - val_loss: 19.7236 - val_mean_IoU: 0.7840 - lr: 0.0012\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3053 - mean_IoU: 0.8775 - val_loss: 19.6082 - val_mean_IoU: 0.7836 - lr: 0.0012\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3219 - mean_IoU: 0.8794 - val_loss: 19.6726 - val_mean_IoU: 0.7864 - lr: 0.0012\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2434 - mean_IoU: 0.8803 - val_loss: 19.8031 - val_mean_IoU: 0.7849 - lr: 0.0012\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2629 - mean_IoU: 0.8789 - val_loss: 20.3513 - val_mean_IoU: 0.7839 - lr: 0.0012\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.2153 - mean_IoU: 0.8789 - val_loss: 19.8102 - val_mean_IoU: 0.7846 - lr: 0.0012\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3058 - mean_IoU: 0.8787 - val_loss: 20.0093 - val_mean_IoU: 0.7841 - lr: 0.0012\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2310 - mean_IoU: 0.8785 - val_loss: 19.8911 - val_mean_IoU: 0.7851 - lr: 0.0012\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2920 - mean_IoU: 0.8787 - val_loss: 19.6333 - val_mean_IoU: 0.7837 - lr: 0.0012\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2674 - mean_IoU: 0.8777 - val_loss: 19.6273 - val_mean_IoU: 0.7844 - lr: 0.0012\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.3014 - mean_IoU: 0.8802 - val_loss: 19.8423 - val_mean_IoU: 0.7827 - lr: 0.0012\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.2790 - mean_IoU: 0.8787 - val_loss: 19.8320 - val_mean_IoU: 0.7858 - lr: 0.0012\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2406 - mean_IoU: 0.8798 - val_loss: 20.2782 - val_mean_IoU: 0.7838 - lr: 0.0012\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2835 - mean_IoU: 0.8778 - val_loss: 20.3469 - val_mean_IoU: 0.7797 - lr: 0.0012\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2241 - mean_IoU: 0.8783 - val_loss: 19.9227 - val_mean_IoU: 0.7823 - lr: 0.0012\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1427 - mean_IoU: 0.8780 - val_loss: 20.2405 - val_mean_IoU: 0.7832 - lr: 0.0012\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2560 - mean_IoU: 0.8789 - val_loss: 20.2845 - val_mean_IoU: 0.7874 - lr: 0.0012\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2928 - mean_IoU: 0.8794 - val_loss: 20.4323 - val_mean_IoU: 0.7843 - lr: 0.0012\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0907 - mean_IoU: 0.8775 - val_loss: 20.2360 - val_mean_IoU: 0.7835 - lr: 0.0012\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2314 - mean_IoU: 0.8778 - val_loss: 20.1155 - val_mean_IoU: 0.7801 - lr: 0.0012\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2472 - mean_IoU: 0.8781 - val_loss: 20.8234 - val_mean_IoU: 0.7847 - lr: 0.0012\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2072 - mean_IoU: 0.8781 - val_loss: 20.4942 - val_mean_IoU: 0.7813 - lr: 0.0012\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2874 - mean_IoU: 0.8787 - val_loss: 20.2334 - val_mean_IoU: 0.7800 - lr: 0.0012\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2560 - mean_IoU: 0.8797 - val_loss: 20.5521 - val_mean_IoU: 0.7834 - lr: 0.0012\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2176 - mean_IoU: 0.8777 - val_loss: 20.2662 - val_mean_IoU: 0.7802 - lr: 0.0012\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2316 - mean_IoU: 0.8794 - val_loss: 20.4661 - val_mean_IoU: 0.7815 - lr: 0.0012\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.2664 - mean_IoU: 0.8793 - val_loss: 20.2684 - val_mean_IoU: 0.7849 - lr: 0.0012\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2427 - mean_IoU: 0.8777 - val_loss: 20.6912 - val_mean_IoU: 0.7827 - lr: 0.0012\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - ETA: 0s - loss: 15.2156 - mean_IoU: 0.8791\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2156 - mean_IoU: 0.8791 - val_loss: 20.0880 - val_mean_IoU: 0.7853 - lr: 0.0012\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2033 - mean_IoU: 0.8793 - val_loss: 20.2956 - val_mean_IoU: 0.7863 - lr: 6.2500e-04\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1942 - mean_IoU: 0.8786 - val_loss: 20.1051 - val_mean_IoU: 0.7850 - lr: 6.2500e-04\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.2034 - mean_IoU: 0.8777 - val_loss: 20.3510 - val_mean_IoU: 0.7839 - lr: 6.2500e-04\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1946 - mean_IoU: 0.8794 - val_loss: 20.1354 - val_mean_IoU: 0.7850 - lr: 6.2500e-04\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1245 - mean_IoU: 0.8777 - val_loss: 20.0199 - val_mean_IoU: 0.7855 - lr: 6.2500e-04\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1714 - mean_IoU: 0.8790 - val_loss: 20.2687 - val_mean_IoU: 0.7856 - lr: 6.2500e-04\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1872 - mean_IoU: 0.8782 - val_loss: 20.2022 - val_mean_IoU: 0.7847 - lr: 6.2500e-04\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1516 - mean_IoU: 0.8805 - val_loss: 19.9089 - val_mean_IoU: 0.7829 - lr: 6.2500e-04\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1199 - mean_IoU: 0.8815 - val_loss: 20.1450 - val_mean_IoU: 0.7818 - lr: 6.2500e-04\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - ETA: 0s - loss: 15.1635 - mean_IoU: 0.8796\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1635 - mean_IoU: 0.8796 - val_loss: 19.8247 - val_mean_IoU: 0.7832 - lr: 6.2500e-04\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1402 - mean_IoU: 0.8789 - val_loss: 19.8031 - val_mean_IoU: 0.7841 - lr: 3.1250e-04\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1810 - mean_IoU: 0.8798 - val_loss: 19.8850 - val_mean_IoU: 0.7841 - lr: 3.1250e-04\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0930 - mean_IoU: 0.8790 - val_loss: 20.0346 - val_mean_IoU: 0.7831 - lr: 3.1250e-04\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0925 - mean_IoU: 0.8791 - val_loss: 19.8925 - val_mean_IoU: 0.7831 - lr: 3.1250e-04\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1814 - mean_IoU: 0.8788 - val_loss: 20.2064 - val_mean_IoU: 0.7831 - lr: 3.1250e-04\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1439 - mean_IoU: 0.8786 - val_loss: 20.1986 - val_mean_IoU: 0.7827 - lr: 3.1250e-04\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1618 - mean_IoU: 0.8791 - val_loss: 20.3982 - val_mean_IoU: 0.7825 - lr: 3.1250e-04\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1156 - mean_IoU: 0.8795 - val_loss: 20.1567 - val_mean_IoU: 0.7837 - lr: 3.1250e-04\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1219 - mean_IoU: 0.8787 - val_loss: 20.2090 - val_mean_IoU: 0.7825 - lr: 3.1250e-04\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - ETA: 0s - loss: 15.1787 - mean_IoU: 0.8793\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1787 - mean_IoU: 0.8793 - val_loss: 20.1648 - val_mean_IoU: 0.7823 - lr: 3.1250e-04\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1516 - mean_IoU: 0.8786 - val_loss: 20.1256 - val_mean_IoU: 0.7819 - lr: 1.5625e-04\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1697 - mean_IoU: 0.8783 - val_loss: 20.1013 - val_mean_IoU: 0.7820 - lr: 1.5625e-04\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1152 - mean_IoU: 0.8783 - val_loss: 20.1467 - val_mean_IoU: 0.7823 - lr: 1.5625e-04\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1602 - mean_IoU: 0.8798 - val_loss: 20.1084 - val_mean_IoU: 0.7833 - lr: 1.5625e-04\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1047 - mean_IoU: 0.8804 - val_loss: 20.1716 - val_mean_IoU: 0.7832 - lr: 1.5625e-04\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1005 - mean_IoU: 0.8778 - val_loss: 20.1440 - val_mean_IoU: 0.7829 - lr: 1.5625e-04\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1724 - mean_IoU: 0.8802 - val_loss: 20.0450 - val_mean_IoU: 0.7832 - lr: 1.5625e-04\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0937 - mean_IoU: 0.8800 - val_loss: 20.1090 - val_mean_IoU: 0.7832 - lr: 1.5625e-04\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1448 - mean_IoU: 0.8801 - val_loss: 20.0682 - val_mean_IoU: 0.7831 - lr: 1.5625e-04\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - ETA: 0s - loss: 15.1294 - mean_IoU: 0.8790\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1294 - mean_IoU: 0.8790 - val_loss: 20.1624 - val_mean_IoU: 0.7829 - lr: 1.5625e-04\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1267 - mean_IoU: 0.8786 - val_loss: 20.1344 - val_mean_IoU: 0.7830 - lr: 7.8125e-05\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1264 - mean_IoU: 0.8800 - val_loss: 20.1143 - val_mean_IoU: 0.7836 - lr: 7.8125e-05\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1264 - mean_IoU: 0.8794 - val_loss: 20.1541 - val_mean_IoU: 0.7838 - lr: 7.8125e-05\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0759 - mean_IoU: 0.8783 - val_loss: 20.2170 - val_mean_IoU: 0.7839 - lr: 7.8125e-05\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1206 - mean_IoU: 0.8790 - val_loss: 20.1539 - val_mean_IoU: 0.7839 - lr: 7.8125e-05\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0946 - mean_IoU: 0.8804 - val_loss: 20.1844 - val_mean_IoU: 0.7836 - lr: 7.8125e-05\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0609 - mean_IoU: 0.8792 - val_loss: 20.1669 - val_mean_IoU: 0.7837 - lr: 7.8125e-05\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1643 - mean_IoU: 0.8792 - val_loss: 20.1969 - val_mean_IoU: 0.7830 - lr: 7.8125e-05\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1196 - mean_IoU: 0.8795 - val_loss: 20.2566 - val_mean_IoU: 0.7829 - lr: 7.8125e-05\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.0667 - mean_IoU: 0.8792 - val_loss: 20.1876 - val_mean_IoU: 0.7834 - lr: 7.8125e-05\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.0861 - mean_IoU: 0.8781 - val_loss: 20.1648 - val_mean_IoU: 0.7835 - lr: 7.8125e-05\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.0958 - mean_IoU: 0.8785 - val_loss: 20.1628 - val_mean_IoU: 0.7836 - lr: 7.8125e-05\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1315 - mean_IoU: 0.8793 - val_loss: 20.1855 - val_mean_IoU: 0.7832 - lr: 7.8125e-05\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1010 - mean_IoU: 0.8793 - val_loss: 20.1515 - val_mean_IoU: 0.7835 - lr: 7.8125e-05\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1224 - mean_IoU: 0.8796 - val_loss: 20.1660 - val_mean_IoU: 0.7836 - lr: 7.8125e-05\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1096 - mean_IoU: 0.8795 - val_loss: 20.0913 - val_mean_IoU: 0.7838 - lr: 7.8125e-05\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - ETA: 0s - loss: 15.1185 - mean_IoU: 0.8794\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1185 - mean_IoU: 0.8794 - val_loss: 19.9903 - val_mean_IoU: 0.7838 - lr: 7.8125e-05\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1408 - mean_IoU: 0.8802 - val_loss: 19.9946 - val_mean_IoU: 0.7837 - lr: 3.9062e-05\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.0951 - mean_IoU: 0.8795 - val_loss: 20.0297 - val_mean_IoU: 0.7835 - lr: 3.9062e-05\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1318 - mean_IoU: 0.8796 - val_loss: 20.0409 - val_mean_IoU: 0.7833 - lr: 3.9062e-05\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1244 - mean_IoU: 0.8789 - val_loss: 20.0496 - val_mean_IoU: 0.7833 - lr: 3.9062e-05\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1166 - mean_IoU: 0.8794 - val_loss: 20.0428 - val_mean_IoU: 0.7834 - lr: 3.9062e-05\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1034 - mean_IoU: 0.8775 - val_loss: 20.0678 - val_mean_IoU: 0.7834 - lr: 3.9062e-05\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0998 - mean_IoU: 0.8798 - val_loss: 20.0822 - val_mean_IoU: 0.7835 - lr: 3.9062e-05\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.0656 - mean_IoU: 0.8789 - val_loss: 20.1069 - val_mean_IoU: 0.7833 - lr: 3.9062e-05\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1577 - mean_IoU: 0.8790 - val_loss: 20.1502 - val_mean_IoU: 0.7830 - lr: 3.9062e-05\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - ETA: 0s - loss: 15.1337 - mean_IoU: 0.8795\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1337 - mean_IoU: 0.8795 - val_loss: 20.1430 - val_mean_IoU: 0.7831 - lr: 3.9062e-05\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0913 - mean_IoU: 0.8786 - val_loss: 20.1420 - val_mean_IoU: 0.7831 - lr: 1.9531e-05\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.0836 - mean_IoU: 0.8797 - val_loss: 20.1306 - val_mean_IoU: 0.7831 - lr: 1.9531e-05\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1279 - mean_IoU: 0.8805 - val_loss: 20.1095 - val_mean_IoU: 0.7830 - lr: 1.9531e-05\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0943 - mean_IoU: 0.8787 - val_loss: 20.1205 - val_mean_IoU: 0.7830 - lr: 1.9531e-05\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0391 - mean_IoU: 0.8793 - val_loss: 20.1202 - val_mean_IoU: 0.7830 - lr: 1.9531e-05\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0633 - mean_IoU: 0.8796 - val_loss: 20.1212 - val_mean_IoU: 0.7831 - lr: 1.9531e-05\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 15.1177 - mean_IoU: 0.8801 - val_loss: 20.1252 - val_mean_IoU: 0.7831 - lr: 1.9531e-05\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1051 - mean_IoU: 0.8791 - val_loss: 20.1216 - val_mean_IoU: 0.7832 - lr: 1.9531e-05\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1198 - mean_IoU: 0.8797 - val_loss: 20.1137 - val_mean_IoU: 0.7831 - lr: 1.9531e-05\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1225 - mean_IoU: 0.8793 - val_loss: 20.1180 - val_mean_IoU: 0.7832 - lr: 1.9531e-05\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1327 - mean_IoU: 0.8788 - val_loss: 20.1228 - val_mean_IoU: 0.7833 - lr: 1.9531e-05\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1232 - mean_IoU: 0.8787 - val_loss: 20.1252 - val_mean_IoU: 0.7833 - lr: 1.9531e-05\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.0623 - mean_IoU: 0.8784 - val_loss: 20.1304 - val_mean_IoU: 0.7833 - lr: 1.9531e-05\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1132 - mean_IoU: 0.8788 - val_loss: 20.1341 - val_mean_IoU: 0.7833 - lr: 1.9531e-05\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - ETA: 0s - loss: 15.1037 - mean_IoU: 0.8799\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1037 - mean_IoU: 0.8799 - val_loss: 20.1080 - val_mean_IoU: 0.7834 - lr: 1.9531e-05\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1037 - mean_IoU: 0.8788 - val_loss: 20.0989 - val_mean_IoU: 0.7833 - lr: 9.7656e-06\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 15.1143 - mean_IoU: 0.8798 - val_loss: 20.0982 - val_mean_IoU: 0.7834 - lr: 9.7656e-06\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 15.1206 - mean_IoU: 0.8790 - val_loss: 20.1064 - val_mean_IoU: 0.7834 - lr: 9.7656e-06\n",
      "INFO:tensorflow:Assets written to: S200_voronoi\\assets\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "callbacks = keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, verbose=1, patience=10, min_lr=1e-6)\n",
    "\n",
    "smooth = 50\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "IoU = tf.keras.metrics.MeanIoU(num_classes=2, name=\"mean_IoU\")\n",
    "\n",
    "if smooth == 0:\n",
    "    loss = keras.losses.BinaryCrossentropy()\n",
    "else:\n",
    "    loss = jaccard_distance(smooth=smooth)\n",
    "\n",
    "n_filters, init_lr, f_activ = 64, 0.005, \"sigmoid\"\n",
    "\n",
    "print(f\"Using loss : {loss}.\")\n",
    "print(f\"Smoothing : {smooth}\")\n",
    "\n",
    "unet = get_unet(n_filters, 512, 512, n_channels_imgs=nc_ims, n_channels_masks=nc_masks, final_activation=f_activ)  # linear for EDM regression\n",
    "\n",
    "unet.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=init_lr),\n",
    "    # loss=keras.losses.BinaryCrossentropy(),\n",
    "    loss=loss,\n",
    "    metrics=IoU,\n",
    "#     metrics=[tf.keras.metrics.MeanSquaredError()],\n",
    ")\n",
    "n_epochs = 200\n",
    "history = unet.fit(generator, validation_data=val_generator, \n",
    "                   epochs=n_epochs, verbose=1, callbacks=callbacks)\n",
    "\n",
    "# plot learning curves\n",
    "ax[0].plot(history.history[\"loss\"][:], \"orange\", label=\"loss\")\n",
    "ax[0].plot(history.history[\"val_loss\"][:], \"b\", label=\"validation loss\")\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Training curves\")\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(f\"Loss (Jaccard, smooth=={smooth})\")\n",
    "# ax[0].set_ylabel(\"Loss (MSE)\")\n",
    "\n",
    "ax[1].plot(history.history[\"mean_IoU\"][:], \"orange\", label=\"IoU\")\n",
    "ax[1].plot(history.history[\"val_mean_IoU\"][:], \"b\", label=\"validation IoU\")\n",
    "# ax[1].plot(history.history[\"mean_squared_error\"][10:], \"orange\", label=\"MSE\")\n",
    "# ax[1].plot(history.history[\"val_mean_squared_error\"][10:], \"b\", label=\"validation MSE\")\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Training curves\")\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"IoU\")\n",
    "\n",
    "# save model\n",
    "model_name = f\"S{n_epochs}_voronoi\"\n",
    "\n",
    "fig.suptitle(model_name)\n",
    "\n",
    "os.chdir(\"D:/Hugo/Whole_Cell/Models\")\n",
    "unet.save(model_name)\n",
    "\n",
    "plt.savefig(f\"{model_name}/{model_name}_learning_curve.png\")\n",
    "\n",
    "list_training_imgs = \"\\n\".join(os.listdir(generator.X_dir))\n",
    "list_val_imgs = \"\\n\".join(os.listdir(val_generator.X_dir))\n",
    "\n",
    "with open(f\"{model_name}/history.txt\", \"w\") as hist_file:\n",
    "    hist_file.write(f\"Model {model_name} trained for {n_epochs} epochs.\"\n",
    "                    f\"\\n\\nFinal activation layer: {f_activ}.\"\n",
    "                    f\"\\n\\nNumber of training images : {len(generator)} * {generator.batch_size}, from directory {generator.X_dir}, masks from {generator.Y_dir}.\"\n",
    "                    f\"\\n\\nNumber of validation images : {len(val_generator)} * {val_generator.batch_size}, from directory {val_generator.X_dir}, masks from {val_generator.Y_dir}.\"\n",
    "                    f\"\\n\\nLoss : {loss}\" #, smoothing: {smooth}.\"\n",
    "                    f\"\\n\\nNumber of filters : {n_filters}.\"\n",
    "                    f\"\\n\\nInitial learning rate: {init_lr}.\"\n",
    "                    f\"\\n\\nList of the training images:\\n{list_training_imgs}.\"\n",
    "                    f\"\\n\\nList of the validation images:\\n{list_val_imgs}.\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference\n",
    "\n",
    "Now we will use the model to make predictions on the test dataset to check if it can generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Generates images and masks for performing data augmentation in Keras.\n",
    "    We inherit from Sequence (instead of directly using the keras ImageDataGenerator)\n",
    "    since we want to perform augmentation on both the input image AND the mask \n",
    "    (target). This mechanism needs to be implemented in this class. This class\n",
    "    also allows to implement new augmentation transforms that are not implemented\n",
    "    in the core Keras class (illumination, etc.).\n",
    "    See : https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    and https://stackoverflow.com/questions/56758592/how-to-customize-imagedatagenerator-in-order-to-modify-the-target-variable-value\n",
    "    for more details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_set, # input images and masks\n",
    "                 n_channels_ims=1, n_channels_masks=1,\n",
    "                 batch_size: int=4, dim: tuple=(512, 512),\n",
    "                 n_channels: int=1, # informations \n",
    "                 normalize=True, reshape=False, crop=None, # preprocessing params\n",
    "                 restrict_to=\"\"): # data augmentation params\n",
    "        \"\"\"\n",
    "        X_set (list, array or str): pointer to the images (Bright-Field). If str\n",
    "        the string is assumed to be pointing at some directory.\n",
    "        Y_set (list; array or str): pointer to the masks (target). If str\n",
    "        the string is assumed to be pointing at some directory.\n",
    "        batch_size (int): size of the batch\n",
    "        dim (tuple): dimension of the images\n",
    "        n_channels (int) : number of channels of the images (1 for TIF)\n",
    "        shuffle (bool): Shuffle the dataset between each training epoch\n",
    "        normalize (bool): normalize the images and masks in the beginning\n",
    "        reshape (bool): reshape the images and masks to (dim, dim, n_channels)\n",
    "        histogram_equalization (bool): perform histogram equalization to improve\n",
    "        rendering using opencv\n",
    "        horiz_flip_percent ()\n",
    "        vert_flip_percent\n",
    "        \"\"\"\n",
    "        # super().__init__(n, batch_size, shuffle, seed)\n",
    "        self.dim = dim\n",
    "        self.im_size = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_channels_ims = n_channels_ims\n",
    "        self.n_channels_masks = n_channels_masks\n",
    "        \n",
    "        \n",
    "        self.restrict_to = restrict_to\n",
    "\n",
    "        # build the X_set in an array. If X_set is a directory containing images\n",
    "        # then self.X_set doesn't contains the images but the file names, but it\n",
    "        # is transparent for the user.\n",
    "        if type(X_set) == list:\n",
    "            self.from_directory_X = False\n",
    "            self.X_set = np.array(X_set)\n",
    "        elif type(X_set) == np.array:\n",
    "            self.from_directory_X = False\n",
    "            self.X_set = X_set           \n",
    "        elif type(X_set) == str: # assuming a path\n",
    "            self.from_directory_X = True\n",
    "            self.X_dir = X_set # path to the images dir\n",
    "            self.X_set = []\n",
    "            if self.restrict_to == \"\":\n",
    "                for k in range(0, len(os.listdir(X_set)), self.n_channels_ims):\n",
    "                    self.X_set.append(np.array(os.listdir(X_set)[k:k+self.n_channels_ims]))\n",
    "                self.X_set = np.array(self.X_set)\n",
    "            else:\n",
    "                for k in range(0, len(os.listdir(X_set)), self.n_channels_ims):\n",
    "                    if os.listdir(X_set)[k].startswith(self.restrict_to):\n",
    "                        self.X_set.append(np.array(os.listdir(X_set)[k:k+self.n_channels_ims]))\n",
    "                self.X_set = np.array(self.X_set)\n",
    "        else:\n",
    "            raise TypeError(\"X_set should be list, array or path\")\n",
    "        \n",
    "        # Preprocessing parameters\n",
    "        self.normalize = normalize\n",
    "        self.reshape = reshape\n",
    "        self.crop = crop\n",
    "        \n",
    "        # Initialize the indices (shuffle if asked)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Number of batches per epoch : we evenly split the train set into samples\n",
    "        of size batch_size.\n",
    "        \"\"\"\n",
    "        return int(np.floor(self.X_set.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"\n",
    "        Generate one batch of data.\n",
    "        \"\"\"\n",
    "        if index >= self.__len__():\n",
    "            raise IndexError\n",
    "            \n",
    "        # Generate indices corresponding to the images in the batch\n",
    "        indices = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate the batch\n",
    "        X = self.__data_generation(indices)\n",
    "        return X\n",
    "    \n",
    "    def get_image_idx(self, im_name):\n",
    "        \"\"\"\n",
    "        Used to sort the images by an idx, when they are properly sorted (e.g. when images\n",
    "        are numbered 1 to 1000 instead of 0001 to 1000). We assume that the numerical index\n",
    "        is in the form \"XXX_tnumericalindex.tiff\" where XXC can be anything.\n",
    "        \"\"\"\n",
    "        if \"-\" in im_name.split(\".\")[0].split(\"_\")[-1][1:]:\n",
    "            return int(im_name.split(\".\")[0].split(\"_\")[-1][1:].split(\"-\")[-1][1:])\n",
    "        else:\n",
    "            return int(im_name.split(\".\")[0].split(\"_\")[-1][1:])\n",
    "        \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Updates indexes after each epoch. self.indexes is used to retrieve the\n",
    "        samples and organize them into batches.\n",
    "        If shuffle : randomizes the order of the samples in order to give \n",
    "        different training batches at each epoch.\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(self.X_set.shape[0])\n",
    "\n",
    "    def __data_generation(self, list_IDs: [int]):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples. This is where we load the\n",
    "        images if they are in a directory, and apply transformations to them.\n",
    "        \"\"\" \n",
    "        # Load data (from directory or from X_set depending on the given data)\n",
    "        if self.from_directory_X:\n",
    "            batch_X = []\n",
    "            for im in list_IDs:\n",
    "                channels = []\n",
    "                for k in range(self.n_channels_ims):\n",
    "                    channels.append(np.expand_dims(imageio.imread(f\"{self.X_dir}/{self.X_set[im, k]}\"), axis=-1)) # add channel axis\n",
    "                batch_X.append(np.concatenate(channels, axis=-1))\n",
    "            batch_X = np.array(batch_X)            \n",
    "        else:\n",
    "            batch_X = self.X_set[list_IDs]\n",
    "\n",
    "        # Preprocessing\n",
    "        if self.crop is not None:\n",
    "            batch_X = self.perf_crop(batch_X)\n",
    "            \n",
    "        if self.reshape:\n",
    "            batch_X = self.perf_reshape(batch_X)\n",
    "\n",
    "        if self.normalize:\n",
    "            batch_X = self.perf_normalize(batch_X)\n",
    "\n",
    "        return batch_X\n",
    "\n",
    "    # Preprocessing functions\n",
    "    def perf_crop(self, images):\n",
    "        crop_X = int((images.shape[1] - self.crop[0]) // 2)\n",
    "        crop_Y = int((images.shape[2] - self.crop[1]) // 2)\n",
    "        new_batch = np.empty((self.batch_size, *self.crop))\n",
    "        for i, img in enumerate(images):\n",
    "            if crop_X != 0 and crop_Y != 0:\n",
    "                new_batch[i] = img[crop_X:-crop_X, crop_Y:-crop_Y]\n",
    "            elif crop_X != 0:\n",
    "                new_batch[i] = img[crop_X:-crop_X, :]\n",
    "            elif crop_Y != 0:\n",
    "                new_batch[i] = img[:, crop_Y:-crop_Y]\n",
    "            else:\n",
    "                new_batch[i] = img\n",
    "        return new_batch\n",
    "    \n",
    "    def perf_reshape(self, images):\n",
    "        \"\"\"\n",
    "        images (np.array): batch of images of shape (batch_size, n_rows, n_cols, n_chans)\n",
    "        is_images (bool): is it a batch of images (True) or masks (False)\n",
    "        \"\"\"\n",
    "        new_batch = np.empty((self.batch_size, *self.im_size, self.n_channels_ims))\n",
    "        for i, img in enumerate(images): # the resize function normalizes the images anyways...\n",
    "            new_batch[i] = skimage.transform.resize(img, (*self.im_size, self.n_channels_ims), anti_aliasing=True)\n",
    "        return new_batch\n",
    "\n",
    "    def perf_normalize(self, images):\n",
    "        \"\"\"\n",
    "        Performs per image, per channel normalization by substracting the min and dividing by (max - min)\n",
    "        \"\"\"\n",
    "        new_batch = np.empty(images.shape)\n",
    "        for i, img in enumerate(images):\n",
    "            assert (np.min(img, axis=(0, 1)) != np.max(img, axis=(0, 1))).all(), print(\"Cannot normalize an image containing only 0 or 1 valued pixels. There is likely an empty image in the training set.\\nIf cropping was used,\"\n",
    "                                                                                       \"maybe the mask doesn't contain any white pixel in the specific region.\")\n",
    "            new_batch[i] = (img - np.min(img, axis=(0, 1))) / (np.max(img, axis=(0, 1)) - np.min(img, axis=(0, 1)))\n",
    "        return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE DATASET PATH HERE\n",
    "test_path = \"D:\\Hugo\\Data\\H449/pos5\\BF_1-120\"\n",
    "# test_path = \"D:\\Hugo\\Data\\BF_f0001/indiv_images\"\n",
    "restrict_to = \"\"\n",
    "bs, n_chan_ims, n_chan_ms = 1, 1, 2\n",
    "test_set = ImageGenerator(test_path, batch_size=bs, dim=(512, 512),\n",
    "                          n_channels_ims=n_chan_ims, n_channels_masks=n_chan_ms, crop=None, normalize=True, reshape=True, restrict_to=restrict_to)\n",
    "\n",
    "plot = False\n",
    "if plot:\n",
    "    visualize_data(test_set[0], np.zeros((1, test_set[0].shape[0], test_set[0].shape[1], 1)), n_chan_ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions duration for 120 images : 4.84 sec.\n",
      "(120, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "predictions = unet.predict(test_set)\n",
    "print(f\"Predictions duration for {predictions.shape[0]} images : {round(time.time() - t0, 2)} sec.\")\n",
    "\n",
    "whole_test_set = np.concatenate([test_set[i] for i in range(len(test_set))], axis=0)\n",
    "print(whole_test_set.shape)\n",
    "\n",
    "def visualize_data_and_predictions(bf, masks, nc_ims=1, nc_masks=1):\n",
    "    with napari.gui_qt():\n",
    "        if nc_ims == 1:\n",
    "            viewer = napari.view_image(bf[:, :, :, :].squeeze(-1))\n",
    "        else:\n",
    "            viewer = napari.view_image(bf[:, :, :, 0])  # bf\n",
    "            for k in range(1, nc_ims):\n",
    "                viewer.add_image(bf[:, :, :, k], blending=\"additive\")\n",
    "        if nc_masks == 1:    \n",
    "            viewer.add_image(masks[:, :, :, :].squeeze(-1), blending=\"additive\")\n",
    "        else:\n",
    "            for k in range(0, nc_masks):\n",
    "                viewer.add_image(masks[:, :, :, k], blending=\"additive\")\n",
    "\n",
    "plot = False\n",
    "if plot:\n",
    "    visualize_data_and_predictions(whole_test_set, predictions, nc_ims=1, nc_masks=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions = True\n",
    "if save_predictions:\n",
    "    # REPLACE TEST SAVE PREDICTIONS PATH\n",
    "    save_path = [\"D:/Hugo/Whole_Cell/Predictions/S200_voronoi_H449_pos5_1-120_01.tif\", \"D:/Hugo/Whole_Cell/Predictions/S200_voronoi_H449_pos5_1-120_02.tif\"]\n",
    "#     predicted_nochan = predictions#.squeeze(-1)\n",
    "    \n",
    "    for k in range(2):\n",
    "        imageio.volwrite(save_path[k], predictions[:, :, :, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: S1\\assets\n"
     ]
    }
   ],
   "source": [
    "# CHANGE SAVE PATH HERE\n",
    "os.chdir(\"D:/Hugo/Whole_Cell/Models/\")\n",
    "unet.save(\"S1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE SAVE MODEL PATH\n",
    "save_model_path = \"/content/gdrive/MyDrive/CYBERSCOPE/Migration/Models\"\n",
    "unet.save(save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_from_scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
