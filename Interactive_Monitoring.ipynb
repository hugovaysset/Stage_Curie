{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive monitoring of cells characteristics\n",
    "\n",
    "Here we want to use the contours produced from the images segmentation, and the tracking results, to be able to investigate the cells' characteristics in a user-friendly fashion, via the Napari GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\napari\\_qt\\__init__.py:37: UserWarning: \n",
      "    napari was tested with QT library `>=5.12.3`.\n",
      "    The version installed is 5.9.7. Please report any issues with this\n",
      "    specific QT version at https://github.com/Napari/napari/issues.\n",
      "    \n",
      "  warn(message=warn_message)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from skimage import measure # to get contours from masks\n",
    "\n",
    "# btrack module and configuration file\n",
    "import btrack\n",
    "from btrack.dataio import localizations_to_objects\n",
    "from btrack.constants import BayesianUpdates\n",
    "from btrack.render import plot_tracks\n",
    "\n",
    "import imagecodecs\n",
    "import napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Here we load several things:\n",
    "* Bright Field images\n",
    "* Predictions made by the model\n",
    "* Corresponding RFP images\n",
    "\n",
    "As well as:\n",
    "* The dataframe containing the tracking results\n",
    "* The array (sorted; with the same rows order as in the dataframe) containing the cells contours at each time step.\n",
    "Those two files were generated in the ```Perform_Tracking.ipynb``` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'D:\\Hugo\\Whole_Cell\\Predictions\\Predictions_UNET110_ep50_f0001_1-20.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bd03390fe40b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/Hugo/Whole_Cell\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# root dir containg Predictions and Images Path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvolread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predictions/Predictions_UNET110_ep50_f0001_1-20.tif\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# neural network predictions (segmentation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcorresponding_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvolread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test_Set/BF_f0001-1_20imgs.tif\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# bf images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrfp_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvolread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/Hugo/Data/F0001/RFP_f0001-1-20.tif\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# rfp images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mvolread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"v\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    258\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'D:\\Hugo\\Whole_Cell\\Predictions\\Predictions_UNET110_ep50_f0001_1-20.tif'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"D:/Hugo/Whole_Cell\")  # root dir containg Predictions and Images Path\n",
    "\n",
    "predictions = imageio.volread(\"Predictions/Predictions_UNET110_ep50_f0001_1-20.tif\") # neural network predictions (segmentation)\n",
    "corresponding_imgs = imageio.volread(\"Test_Set/BF_f0001-1_20imgs.tif\") # bf images\n",
    "rfp_imgs = imageio.volread(\"D:/Hugo/Data/F0001/RFP_f0001-1-20.tif\") # rfp images\n",
    "\n",
    "tracks_and_contours = pd.read_csv(\"D:/Hugo/Python_Scripts/Notebooks/Tracking_Results.csv\") # tracking positions and the corresponding contours\n",
    "contours = np.load(\"D:/Hugo/Python_Scripts/Notebooks/contours.npy\", allow_pickle=True)\n",
    "\n",
    "# a bit dirty... I have to replace the contours in dataframe because if loaded from a csv, it will be a string and not an array\n",
    "# so we save it as a separate array (but with god rows order, see Perform_Tracking.py) and load and cast it to float-32 (for opencv)\n",
    "contours32 = []\n",
    "for c in contours:\n",
    "    cont = []\n",
    "    for pos in c:\n",
    "        cont.append(pos.astype(np.float32))\n",
    "    contours32.append(np.array(cont))\n",
    "contours32 = np.array(contours32)\n",
    "\n",
    "# put the \"good\" contours i.e. the array, and not the loaded string\n",
    "tracks_and_contours = tracks_and_contours.drop(\"Contours\", axis=1)\n",
    "tracks_and_contours[\"Contours\"] = contours32\n",
    "\n",
    "print(tracks_and_contours.shape, contours.shape)\n",
    "tracks_and_contours.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the contours of a specified cell, for all frame\n",
    "ID = 38\n",
    "contours = tracks_and_contours[tracks_and_contours[\"ID\"] == ID][[\"Frame\", \"Contours\"]]\n",
    "print(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the contours of a specified cell, at a specified frame\n",
    "ID, frame = 38, 19\n",
    "contours = tracks_and_contours[(tracks_and_contours[\"ID\"] == ID) & (tracks_and_contours[\"Frame\"] == frame)][\"Contours\"]\n",
    "print(f\"Contours of cell {ID} at frame {frame} : {contours}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive viewer in Napari\n",
    "\n",
    "Here we implement functions to view the predictions and tracking results using the Napari interface. This interface even allows to go further, by allowing the user to click on the cell on which she/he wants to investigate, by plotting several characteristics (surface, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cells_characteristics(tracks_contours, ID, characteristics=[\"Surface\"]):\n",
    "    \"\"\"\n",
    "    Given the ID of a cell, plots the demanded characteristics over time.\n",
    "    tracks_contours (pd.DataFrame): df containing the tracks and the contours of all cells at all frames (ID, Frame, X, Y, Contours)\n",
    "    ID (int): ID of the cell(s) to track. TODO : extend to take a list of IDs instead of a single one.\n",
    "    characteristics (list<str>): List of the characteristics to plot\n",
    "    start_frame (int): first frame to display (included)\n",
    "    end_frame (int): last frame to display (excluded)\n",
    "    \"\"\"\n",
    "    cell = tracks_contours[(tracks_contours[\"ID\"] == ID)]\n",
    "\n",
    "    fig, ax = plt.subplots(1, len(characteristics), figsize=(20, 10))\n",
    "    if \"Surface\" in characteristics:\n",
    "        surfaces_per_frame = retrieve_surfaces(cell) # dataframe containing the cell's surface over time (frame by frame)\n",
    "        start_frame, end_frame = 1000, -1\n",
    "        for ID in pd.unique(surfaces_per_frame[\"ID\"]): # for each cell, plot its surface over time\n",
    "            start_frame, end_frame = np.min([start_frame, np.min(surfaces_per_frame[\"Frame\"])]), np.max([end_frame, np.max(surfaces_per_frame[\"Frame\"])])\n",
    "            if len(characteristics) > 1:\n",
    "                ax[0].plot(surfaces_per_frame[\"Frame\"], surfaces_per_frame[\"Surface\"], label=ID)\n",
    "                ax[0].set_xlim(left=start_frame, right=end_frame)\n",
    "                ax[0].set_title(f\"Surface of cell {ID} between frame {start_frame} and {end_frame}\")\n",
    "                plt.xticks(range(int(start_frame), int(end_frame) + 1))\n",
    "            else:\n",
    "                ax.plot(surfaces_per_frame[\"Frame\"], surfaces_per_frame[\"Surface\"], label=ID)\n",
    "                ax.set_xlim(left=np.min(surfaces_per_frame[\"Frame\"]), right=np.max(surfaces_per_frame[\"Frame\"]))\n",
    "                ax.set_title(f\"Surface of cell {ID} between frame {start_frame} and {end_frame}\")\n",
    "                plt.xticks(range(int(start_frame), int(end_frame) + 1))\n",
    "\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def retrieve_surfaces(cell):\n",
    "    \"\"\"\n",
    "    Retrieve the surface of a cell, whose contours are given in the dataframe cell.\n",
    "    cell (pd.DataFrame): df containing the contours of the query cell.\n",
    "    \"\"\"\n",
    "    surfaces_over_time = []\n",
    "    for i, line in cell.iterrows():\n",
    "        s = cv2.contourArea(line[\"Contours\"])\n",
    "        surfaces_over_time.append({\"ID\": line[\"ID\"], \"Frame\": line[\"Frame\"], \"Surface\": s})\n",
    "    return pd.DataFrame(surfaces_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = []\n",
    "for im in corresponding_imgs:\n",
    "    resized.append(cv2.resize(im, (512, 512)))\n",
    "resized = np.array(resized)\n",
    "\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.view_image(resized, name=\"BF Images\")\n",
    "    rfp_layer = viewer.add_image(rfp_imgs, blending=\"additive\", colormap=\"red\", name=\"RFP Images\")\n",
    "    images_layer = viewer.add_image(predictions, opacity=0.5, colormap=\"bop blue\", blending=\"additive\", name=\"Predictions\")\n",
    "    viewer.add_tracks(tracks_and_contours[[\"ID\", \"Frame\", \"X\", \"Y\"]], name=\"Tracks\")\n",
    "    IDs = []\n",
    "    \n",
    "    @viewer.mouse_drag_callbacks.append\n",
    "    def cells_characteristics(img, event):\n",
    "        \"\"\"\n",
    "        Encapsulate the call to plot_cells_characteristics and implements the user graphical interactions with the Napari GUI. \n",
    "        \"\"\"\n",
    "        frame, x, y = np.round(images_layer.coordinates).astype(int)\n",
    "        \n",
    "        def get_closest_cell(frame, x, y):\n",
    "            \"\"\"\n",
    "            Find the closest cell to click point\n",
    "            Return : ID of the track corresponding to the closest cell\n",
    "            \"\"\"\n",
    "            distances = []\n",
    "            for _, c in tracks_and_contours[tracks_and_contours[\"Frame\"] == frame].iterrows():\n",
    "                distances.append(np.sqrt((c[\"X\"] - x) ** 2 + (c[\"Y\"] - y) ** 2))\n",
    "            distances = np.array(distances)\n",
    "            min_dist, min_dist_arg = np.min(distances), np.argmin(distances)\n",
    "            if min_dist < 12:\n",
    "                closest_cell = tracks_and_contours[tracks_and_contours[\"Frame\"] == frame].iloc[min_dist_arg] # retrieve the closes cell\n",
    "            else: # don't get the closest, the click was just to move on the map\n",
    "                return -1\n",
    "            return closest_cell[\"ID\"]\n",
    "        \n",
    "        ID = get_closest_cell(frame, x, y)\n",
    "        \n",
    "        if ID == -1:\n",
    "            return\n",
    "        else:\n",
    "            IDs.append(ID)\n",
    "            print(IDs)\n",
    "#             viewer.add_shapes(tracks_and_contours[(tracks_and_contours[\"ID\"] == ID)][\"Contours\"].to_numpy(), shape_type=\"polygon\")\n",
    "            plot_cells_characteristics(tracks_and_contours, ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
