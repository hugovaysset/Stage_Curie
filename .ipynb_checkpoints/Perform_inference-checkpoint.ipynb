{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform inference on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model, layers, models\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import Iterator, ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import Iterator, ImageDataGenerator\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import skimage.transform\n",
    "\n",
    "import napari\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Here we load the test set of Bright Field images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Generates images and masks for performing data augmentation in Keras.\n",
    "    We inherit from Sequence (instead of directly using the keras ImageDataGenerator)\n",
    "    since we want to perform augmentation on both the input image AND the mask \n",
    "    (target). This mechanism needs to be implemented in this class. This class\n",
    "    also allows to implement new augmentation transforms that are not implemented\n",
    "    in the core Keras class (illumination, etc.).\n",
    "    See : https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    and https://stackoverflow.com/questions/56758592/how-to-customize-imagedatagenerator-in-order-to-modify-the-target-variable-value\n",
    "    for more details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_set, # input images and masks\n",
    "                 n_channels_ims=1, n_channels_masks=1,\n",
    "                 batch_size: int=4, dim: tuple=(512, 512),\n",
    "                 n_channels: int=1, # informations \n",
    "                 normalize=True, reshape=False, crop=None, # preprocessing params\n",
    "                 restrict_to=\"\"): # data augmentation params\n",
    "        \"\"\"\n",
    "        X_set (list, array or str): pointer to the images (Bright-Field). If str\n",
    "        the string is assumed to be pointing at some directory.\n",
    "        Y_set (list; array or str): pointer to the masks (target). If str\n",
    "        the string is assumed to be pointing at some directory.\n",
    "        batch_size (int): size of the batch\n",
    "        dim (tuple): dimension of the images\n",
    "        n_channels (int) : number of channels of the images (1 for TIF)\n",
    "        shuffle (bool): Shuffle the dataset between each training epoch\n",
    "        normalize (bool): normalize the images and masks in the beginning\n",
    "        reshape (bool): reshape the images and masks to (dim, dim, n_channels)\n",
    "        histogram_equalization (bool): perform histogram equalization to improve\n",
    "        rendering using opencv\n",
    "        horiz_flip_percent ()\n",
    "        vert_flip_percent\n",
    "        \"\"\"\n",
    "        # super().__init__(n, batch_size, shuffle, seed)\n",
    "        self.dim = dim\n",
    "        self.im_size = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_channels_ims = n_channels_ims\n",
    "        self.n_channels_masks = n_channels_masks\n",
    "        \n",
    "        \n",
    "        self.restrict_to = restrict_to\n",
    "\n",
    "        # build the X_set in an array. If X_set is a directory containing images\n",
    "        # then self.X_set doesn't contains the images but the file names, but it\n",
    "        # is transparent for the user.\n",
    "        if type(X_set) == list:\n",
    "            self.from_directory_X = False\n",
    "            self.X_set = np.array(X_set)\n",
    "        elif type(X_set) == np.array:\n",
    "            self.from_directory_X = False\n",
    "            self.X_set = X_set           \n",
    "        elif type(X_set) == str: # assuming a path\n",
    "            self.from_directory_X = True\n",
    "            self.X_dir = X_set # path to the images dir\n",
    "            self.X_set = []\n",
    "            if self.restrict_to == \"\":\n",
    "                for k in range(0, len(os.listdir(X_set)), self.n_channels_ims):\n",
    "                    self.X_set.append(np.array(os.listdir(X_set)[k:k+self.n_channels_ims]))\n",
    "                self.X_set = np.array(self.X_set)\n",
    "            else:\n",
    "                for k in range(0, len(os.listdir(X_set)), self.n_channels_ims):\n",
    "                    if os.listdir(X_set)[k].startswith(self.restrict_to):\n",
    "                        self.X_set.append(np.array(os.listdir(X_set)[k:k+self.n_channels_ims]))\n",
    "                self.X_set = np.array(self.X_set)\n",
    "        else:\n",
    "            raise TypeError(\"X_set should be list, array or path\")\n",
    "        \n",
    "        # Preprocessing parameters\n",
    "        self.normalize = normalize\n",
    "        self.reshape = reshape\n",
    "        self.crop = crop\n",
    "        \n",
    "        # Initialize the indices (shuffle if asked)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Number of batches per epoch : we evenly split the train set into samples\n",
    "        of size batch_size.\n",
    "        \"\"\"\n",
    "        return int(np.floor(self.X_set.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"\n",
    "        Generate one batch of data.\n",
    "        \"\"\"\n",
    "        if index >= self.__len__():\n",
    "            raise IndexError\n",
    "            \n",
    "        # Generate indices corresponding to the images in the batch\n",
    "        indices = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate the batch\n",
    "        X = self.__data_generation(indices)\n",
    "        return X\n",
    "    \n",
    "    def get_image_idx(self, im_name):\n",
    "        \"\"\"\n",
    "        Used to sort the images by an idx, when they are properly sorted (e.g. when images\n",
    "        are numbered 1 to 1000 instead of 0001 to 1000). We assume that the numerical index\n",
    "        is in the form \"XXX_tnumericalindex.tiff\" where XXC can be anything.\n",
    "        \"\"\"\n",
    "        if \"-\" in im_name.split(\".\")[0].split(\"_\")[-1][1:]:\n",
    "            return int(im_name.split(\".\")[0].split(\"_\")[-1][1:].split(\"-\")[-1][1:])\n",
    "        else:\n",
    "            return int(im_name.split(\".\")[0].split(\"_\")[-1][1:])\n",
    "        \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Updates indexes after each epoch. self.indexes is used to retrieve the\n",
    "        samples and organize them into batches.\n",
    "        If shuffle : randomizes the order of the samples in order to give \n",
    "        different training batches at each epoch.\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(self.X_set.shape[0])\n",
    "\n",
    "    def __data_generation(self, list_IDs: [int]):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples. This is where we load the\n",
    "        images if they are in a directory, and apply transformations to them.\n",
    "        \"\"\" \n",
    "        # Load data (from directory or from X_set depending on the given data)\n",
    "        if self.from_directory_X:\n",
    "            batch_X = []\n",
    "            for im in list_IDs:\n",
    "                channels = []\n",
    "                for k in range(self.n_channels_ims):\n",
    "                    channels.append(np.expand_dims(imageio.imread(f\"{self.X_dir}/{self.X_set[im, k]}\"), axis=-1)) # add channel axis\n",
    "                batch_X.append(np.concatenate(channels, axis=-1))\n",
    "            batch_X = np.array(batch_X)            \n",
    "        else:\n",
    "            batch_X = self.X_set[list_IDs]\n",
    "\n",
    "        # Preprocessing\n",
    "        if self.crop is not None:\n",
    "            batch_X = self.perf_crop(batch_X)\n",
    "            \n",
    "        if self.reshape:\n",
    "            batch_X = self.perf_reshape(batch_X)\n",
    "\n",
    "        if self.normalize:\n",
    "            batch_X = self.perf_normalize(batch_X)\n",
    "\n",
    "        return batch_X\n",
    "\n",
    "    # Preprocessing functions\n",
    "    def perf_crop(self, images):\n",
    "        crop_X = int((images.shape[1] - self.crop[0]) // 2)\n",
    "        crop_Y = int((images.shape[2] - self.crop[1]) // 2)\n",
    "        new_batch = np.empty((self.batch_size, *self.crop))\n",
    "        for i, img in enumerate(images):\n",
    "            if crop_X != 0 and crop_Y != 0:\n",
    "                new_batch[i] = img[crop_X:-crop_X, crop_Y:-crop_Y]\n",
    "            elif crop_X != 0:\n",
    "                new_batch[i] = img[crop_X:-crop_X, :]\n",
    "            elif crop_Y != 0:\n",
    "                new_batch[i] = img[:, crop_Y:-crop_Y]\n",
    "            else:\n",
    "                new_batch[i] = img\n",
    "        return new_batch\n",
    "    \n",
    "    def perf_reshape(self, images):\n",
    "        \"\"\"\n",
    "        images (np.array): batch of images of shape (batch_size, n_rows, n_cols, n_chans)\n",
    "        is_images (bool): is it a batch of images (True) or masks (False)\n",
    "        \"\"\"\n",
    "        new_batch = np.empty((self.batch_size, *self.im_size, self.n_channels_ims))\n",
    "        for i, img in enumerate(images): # the resize function normalizes the images anyways...\n",
    "            new_batch[i] = skimage.transform.resize(img, (*self.im_size, self.n_channels_ims), anti_aliasing=True)\n",
    "        return new_batch\n",
    "\n",
    "    def perf_normalize(self, images):\n",
    "        \"\"\"\n",
    "        Performs per image, per channel normalization by substracting the min and dividing by (max - min)\n",
    "        \"\"\"\n",
    "        new_batch = np.empty(images.shape)\n",
    "        for i, img in enumerate(images):\n",
    "            assert (np.min(img, axis=(0, 1)) != np.max(img, axis=(0, 1))).all(), print(\"Cannot normalize an image containing only 0 or 1 valued pixels. There is likely an empty image in the training set.\\nIf cropping was used,\"\n",
    "                                                                                       \"maybe the mask doesn't contain any white pixel in the specific region.\")\n",
    "            new_batch[i] = (img - np.min(img, axis=(0, 1))) / (np.max(img, axis=(0, 1)) - np.min(img, axis=(0, 1)))\n",
    "        return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Batches : 114\n"
     ]
    }
   ],
   "source": [
    "# CHANGE DATASET PATH HERE\n",
    "test_path = \"D:\\Hugo\\Whole_Cell\\\\Train_Set\\images\"\n",
    "\n",
    "restrict_to = \"\"\n",
    "bat_size, nc_ims, nc_masks = 1, 1, 1 # SPECIFY HERE THE NUMBER OF CHANNELS\n",
    "crop, reshape, target_dim, normalize = None, True, (512, 512), True\n",
    "\n",
    "test_set = ImageGenerator(test_path, batch_size=bat_size, dim=target_dim, n_channels_ims=nc_ims, \n",
    "                          n_channels_masks=nc_masks, normalize=normalize, \n",
    "                          reshape=reshape, crop=crop, restrict_to=restrict_to)\n",
    "\n",
    "def visualize_data(bf, nc_ims=1):\n",
    "    with napari.gui_qt():\n",
    "        if nc_ims == 1:\n",
    "            viewer = napari.view_image(bf[:, :, :, :].squeeze(-1))\n",
    "        else:\n",
    "            viewer = napari.view_image(bf[:, :, :, 1])  # bf\n",
    "            viewer.add_image(bf[:, :, :, 0], blending=\"additive\")\n",
    "\n",
    "plot = True\n",
    "if plot:\n",
    "    print(f\"# Batches : {len(test_set)}\")\n",
    "    bf = np.array(test_set[50])    \n",
    "    visualize_data(bf, nc_ims=nc_ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contaminated = False\n",
    "# train_dir = os.listdir(\"D:/Hugo/Python_Scripts/Tools/unet/training_sets/budding/images\")\n",
    "# for test_im in os.listdir(\"D:\\Hugo\\Data\\F0001\\indiv_images\"):\n",
    "#     if test_im in train_dir:\n",
    "#         contaminated = True\n",
    "#         print(f\"Image {test_im} used for evaluation was found in the training set.\")\n",
    "        \n",
    "# if not contaminated:\n",
    "#     print(\"Test set is clean.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25mVak8tBmen"
   },
   "source": [
    "## Load model and perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'groups')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-11593a32cf75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/Hugo/Mammal/Models/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[0munet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"M400\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"jaccard_distance_fixed\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mjaccard_distance\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m   raise IOError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, compile)\u001b[0m\n\u001b[0;32m    114\u001b[0m   \u001b[1;31m# TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m   \u001b[1;31m# TODO(kathywu): Add code to load from objects that contain all endpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m   \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader_cls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[0mobject_graph_proto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m       loader = loader_cls(object_graph_proto,\n\u001b[0m\u001b[0;32m    603\u001b[0m                           \u001b[0msaved_model_proto\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m                           export_dir)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_models_to_reconstruct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;31m# Now that the node object has been fully loaded, and the checkpoint has\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir)\u001b[0m\n\u001b[0;32m    121\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_functions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_WrapperFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcrete_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_load_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;31m# loaded from config may create variables / other objects during\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;31m# initialization. These are recorded in `_nodes_recreated_from_config`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layer_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;31m# Load all other nodes and functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_load_layers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m       \u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetric_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_load_layer\u001b[1;34m(self, proto, node_id)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;31m# Detect whether this object can be revived from the config. If not, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;31m# revive from the SavedModel instead.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m     \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_revive_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m       \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrevive_custom_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_revive_from_config\u001b[1;34m(self, identifier, metadata, node_id)\u001b[0m\n\u001b[0;32m    351\u001b[0m       obj = (\n\u001b[0;32m    352\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_revive_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m           self._revive_layer_from_config(metadata, node_id))\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_revive_layer_from_config\u001b[1;34m(self, metadata, node_id)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m       obj = layers_module.deserialize(\n\u001b[0m\u001b[0;32m    408\u001b[0m           generic_utils.serialize_keras_class_and_config(class_name, config))\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_DESERIALIZATION_TABLE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_class_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m   return deserialize_keras_object(\n\u001b[0m\u001b[0;32m    106\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    373\u001b[0m                 list(custom_objects.items())))\n\u001b[0;32m    374\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m       \u001b[1;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     \"\"\"\n\u001b[1;32m--> 655\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m                \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m                **kwargs):\n\u001b[1;32m--> 582\u001b[1;33m     super(Conv2D, self).__init__(\n\u001b[0m\u001b[0;32m    583\u001b[0m         \u001b[0mrank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                **kwargs):\n\u001b[1;32m--> 121\u001b[1;33m     super(Conv, self).__init__(\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     }\n\u001b[0;32m    293\u001b[0m     \u001b[1;31m# Validate optional keyword arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m     \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;31m# Mutable properties\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[1;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[0;32m    790\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'groups')"
     ]
    }
   ],
   "source": [
    "# CHANGE MODEL PATH HERE\n",
    "# os.chdir(\"D:/Hugo/Python_Scripts/Tools/unet/models\")\n",
    "\n",
    "def binary_focal_loss_fixed(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    :param y_true: A tensor of the same shape as `y_pred`\n",
    "    :param y_pred:  A tensor resulting from a sigmoid\n",
    "    :return: Output tensor.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "    epsilon = K.epsilon()\n",
    "    # Add the epsilon to prediction value\n",
    "    # y_pred = y_pred + epsilon\n",
    "    # Clip the prediciton value\n",
    "    y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "    # Calculate p_t\n",
    "    p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "    # Calculate alpha_t\n",
    "    alpha_factor = K.ones_like(y_true) * alpha\n",
    "    alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "    # Calculate cross entropy\n",
    "    cross_entropy = -K.log(p_t)\n",
    "    weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "    # Calculate focal loss\n",
    "    loss = weight * cross_entropy\n",
    "    # Sum the losses in mini_batch\n",
    "    loss = K.mean(K.sum(loss, axis=1))\n",
    "    return loss\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "    FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "    where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "    model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        # y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.mean(K.sum(loss, axis=1))\n",
    "        return loss\n",
    "    return binary_focal_loss_fixed\n",
    "\n",
    "def jaccard_distance(smooth=50):\n",
    "\n",
    "    def jaccard_distance_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculates mean of Jaccard distance as a loss function\n",
    "        \"\"\"\n",
    "        intersection = tf.reduce_sum(y_true * y_pred, axis=(1,2))\n",
    "        sum_ = tf.reduce_sum(y_true + y_pred, axis=(1,2))\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        jd =  (1 - jac) * smooth\n",
    "        return tf.reduce_mean(jd)\n",
    "    \n",
    "    return jaccard_distance_fixed\n",
    "\n",
    "os.chdir(\"D:/Hugo/Mammal/Models/\")\n",
    "unet = keras.models.load_model(\"M400\", custom_objects={\"jaccard_distance_fixed\": jaccard_distance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTHING TO CHANGE HERE\n",
    "# For 3-channels models\n",
    "predictions = unet.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View results with Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "# CHANGE RFP PATH HERE\n",
    "show_rfp = False  # Change this bool if you don't want to show the RFP channel\n",
    "if show_rfp:\n",
    "    rfp_path = \"D:\\Hugo\\Data\\\\20210428_HugoFirst449\\pos2\\RFP_1-120.tif\"\n",
    "    rfp_imgs = imageio.volread(rfp_path)\n",
    "\n",
    "whole_test_set = np.concatenate([test_set[i] for i in range(len(test_set))], axis=0)\n",
    "print(whole_test_set.shape)\n",
    "\n",
    "import napari\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.view_image(whole_test_set)\n",
    "    \n",
    "    if show_rfp:\n",
    "        rfp_layer = viewer.add_image(rfp_imgs, blending=\"additive\", colormap=\"red\")\n",
    "        \n",
    "    images_layer = viewer.add_image(predictions, opacity=0.5, colormap=\"bop blue\", blending=\"additive\", name=\"S0 predictions\")\n",
    "#     viewer.add_tracks(tracks_and_contours[[\"ID\", \"Frame\", \"X\", \"Y\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd-dyekVZ5ZN"
   },
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "# CHANGE SAVE PATH PATH HERE\n",
    "save_path = \"D:/Hugo/Nucleus/Predictions/Nuc300-H449_1_1-120.tif\"\n",
    "\n",
    "# Rescale image\n",
    "target_dim = (512, 512)\n",
    "predictions_to_save = []\n",
    "for im in predictions:\n",
    "    if target_dim != im.squeeze(-1).shape:\n",
    "        predictions_to_save.append(resize(im.squeeze(-1), target_dim), order=3) # order = 3 :bicubic interpolation\n",
    "    else:\n",
    "        predictions_to_save.append(im.squeeze(-1))\n",
    "predictions_to_save = np.array(predictions_to_save)\n",
    "\n",
    "imageio.volwrite(save_path, predictions_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Perform_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
