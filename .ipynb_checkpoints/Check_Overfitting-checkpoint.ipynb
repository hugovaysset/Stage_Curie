{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the model can overfit the data for this task\n",
    "\n",
    "When starting to work on a new task in Deep Learning, it is good practice to try to overfit our data by training the full model on a single image and validating it on a single image. The expected behaviour is that the model should quickly overfit the data, i.e. making a perfect precision on the training while having a score on the validation image that should be close to a random guess (e.g. the classical crossentropy loss should then be around $- 0.5 \\times log(0.5) - (1 - 0.5) \\times log(1 - 0.5) = 0.69 $). If the model cannot overfit the single image, then its capacity is too small, i.e. the architecture needs to be upscaled or there a bug somewhere. For semantic segmentation, another phenomenon at initialization could be that the loss is over 1 (around 2, 3 up to 6). This translates the fact that the model is heavily saturated at first, i.e. it is heavily biased towards one class and predicts only 1 or 0 for the whole image, thus hurting the covergence speed. \n",
    "\n",
    "I suppose that the \"overfitting sanity-check\" gives an idea of the convergence speed (for the budding task, it took a lot of epochs to overfit this image, and the model was also very long to train on the whole dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model, layers, models\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.preprocessing.image import Iterator, ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras.preprocessing.image import Iterator, ImageDataGenerator\n",
    "import keras.backend as K\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# DRIVE\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "import sys\n",
    "sys.path.append('/content/gdrive/My Drive/CYBERSCOPE/')\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, resize=(512, 512), scale=True, n_channels=1):\n",
    "    \"\"\"\n",
    "    Function to preprocess data : reshape, normalize and expand dims\n",
    "    \"\"\"\n",
    "    # resize\n",
    "    reshaped = cv2.resize(im, target_dim)\n",
    "\n",
    "    # scale\n",
    "    scaled = (reshaped - reshaped.min()) / (reshaped.max() - reshaped.min())\n",
    "\n",
    "    # expand dims\n",
    "    preprocessed = np.expand_dims(np.expand_dims(scaled, axis=-1), axis=0)\n",
    "\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE TRAIN SET PATH\n",
    "bf_path, mask_path = \"/content/gdrive/MyDrive/CYBERSCOPE/Budding/Train_Set/images/...\", \"/content/gdrive/MyDrive/CYBERSCOPE/Budding/Train_Set/masks/...\"\n",
    "\n",
    "img, mask = preprocess_images(imageio.imread(bf_path)),  preprocess_images(imageio.imread(mask_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(bf, masks):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "    axes.imshow(img.squeeze(0).squeeze(-1), cmap=\"Greys\")\n",
    "    axes.imshow(masks[i].squeeze(0).squeeze(-1), alpha=0.5, cmap=\"Spectral\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_data(im, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(nbr,x,y):\n",
    "    \"\"\"\n",
    "    nbr (int): kernel side\n",
    "    x (int): image height\n",
    "    y (int): image width\n",
    "    \"\"\"\n",
    "    initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "    entree=layers.Input(shape=(x, y, 1), dtype='float16')\n",
    "\n",
    "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(entree)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result1=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.MaxPool2D()(result1)\n",
    "\n",
    "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result2=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.MaxPool2D()(result2)\n",
    "\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result3=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.MaxPool2D()(result3)\n",
    "\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result4=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.MaxPool2D()(result4)\n",
    "\n",
    "    result=layers.Conv2D(8*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.UpSampling2D()(result)\n",
    "    result=tf.concat([result, result4], axis=3)\n",
    "\n",
    "    result=layers.Conv2D(8*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.UpSampling2D()(result)\n",
    "    result=tf.concat([result, result3], axis=3)\n",
    "\n",
    "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.UpSampling2D()(result)\n",
    "    result=tf.concat([result, result2], axis=3)\n",
    "\n",
    "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "\n",
    "    result=layers.UpSampling2D()(result)\n",
    "    result=tf.concat([result, result1], axis=3)\n",
    "\n",
    "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "#     result=layers.Dropout(0.2)\n",
    "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same', kernel_initializer=initializer)(result)\n",
    "    result=layers.BatchNormalization()(result)\n",
    "\n",
    "    sortie=layers.Conv2D(1, 1, activation='sigmoid', padding='same', kernel_initializer=initializer)(result)\n",
    "\n",
    "    model=models.Model(inputs=entree, outputs=sortie)\n",
    "    return model\n",
    "\n",
    "unet = get_unet(64, 512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "unet.fit(img, mask, epochs=500, steps_per_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = unet.predict(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(img, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
